#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
SOLAR-10.7B LoRA í•™ìŠµ - Validation í¬í•¨ ê°œì„  ë²„ì „
- Train/Val ë¶„ë¦¬
- Validation loss ê¸°ë°˜ Early Stopping
- ìƒì„¸ ë©”íŠ¸ë¦­ ë¡œê¹…
"""

import sys
import os

# bitsandbytes ì°¨ë‹¨
os.environ['BITSANDBYTES_NOWELCOME'] = '1'
sys.modules['bitsandbytes'] = None

import torch
import json
from pathlib import Path
from transformers import AutoTokenizer, AutoModelForCausalLM
from peft import LoraConfig, get_peft_model, TaskType
from torch.utils.data import Dataset, DataLoader
from tqdm import tqdm
from datetime import datetime
import numpy as np

print("="*80)
print("SOLAR-10.7B LoRA í•™ìŠµ - Validation ê°œì„  ë²„ì „")
print("="*80)

# ============================================
# ì„¤ì •
# ============================================
WORK_DIR = Path("/home/work/LLM_Meditron/bigdataAI")
MODEL_PATH = WORK_DIR / "solar_10.7b_package" / "model"
DATA_PATH = WORK_DIR / "workspace" / "data" / "hira" / "cleaned_data"
OUTPUT_PATH = WORK_DIR / "workspace" / "models" / "solar_hira_v3"
OUTPUT_PATH.mkdir(parents=True, exist_ok=True)

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"\nğŸ“Š í™˜ê²½:")
print(f"  Device: {device}")
print(f"  PyTorch: {torch.__version__}")
if torch.cuda.is_available():
    print(f"  GPU: {torch.cuda.get_device_name(0)}")
    print(f"  VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")

# ============================================
# í•™ìŠµ ì„¤ì • - ê°œì„ ëœ íŒŒë¼ë¯¸í„°
# ============================================
config = {
    "batch_size": 2,
    "gradient_accumulation_steps": 4,
    "learning_rate": 5e-5,
    "num_epochs": 15,  # ì¦ê°€
    "max_length": 512,
    "warmup_steps": 100,
    "logging_steps": 10,
    "eval_steps": 50,  # Validation ì£¼ê¸°
    "patience": 5,     # Early stopping patience ì¦ê°€
}

print(f"\nâš™ï¸  í•™ìŠµ ì„¤ì •:")
for k, v in config.items():
    print(f"  {k}: {v}")

# ============================================
# Dataset í´ë˜ìŠ¤
# ============================================
class HIRADataset(Dataset):
    def __init__(self, file_path, tokenizer, max_length=512):
        self.data = []
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    self.data.append(json.loads(line.strip()))
                except:
                    continue
        
        self.tokenizer = tokenizer
        self.max_length = max_length
        
        print(f"ğŸ“‚ Loaded {len(self.data)} examples from {file_path.name}")
    
    def __len__(self):
        return len(self.data)
    
    def __getitem__(self, idx):
        item = self.data[idx]
        instruction = item['instruction'].strip()
        output = item['output'].strip()
        
        prompt = f"### Instruction:\n{instruction}\n\n### Response:\n{output}"
        
        encoding = self.tokenizer(
            prompt,
            max_length=self.max_length,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        
        return {
            'input_ids': encoding['input_ids'].squeeze(),
            'attention_mask': encoding['attention_mask'].squeeze(),
            'labels': encoding['input_ids'].squeeze()
        }

# ============================================
# Evaluation í•¨ìˆ˜
# ============================================
def evaluate(model, val_loader, device):
    """Validation í‰ê°€"""
    model.eval()
    total_loss = 0
    num_batches = 0
    
    with torch.no_grad():
        for batch in tqdm(val_loader, desc="Validating", leave=False):
            input_ids = batch['input_ids'].to(device)
            attention_mask = batch['attention_mask'].to(device)
            labels = batch['labels'].to(device)
            
            outputs = model(
                input_ids=input_ids,
                attention_mask=attention_mask,
                labels=labels
            )
            
            total_loss += outputs.loss.item()
            num_batches += 1
    
    model.train()
    return total_loss / num_batches

# ============================================
# ëª¨ë¸ ë¡œë“œ
# ============================================
print(f"\nğŸ”„ ëª¨ë¸ ë¡œë”©...")
print(f"  Path: {MODEL_PATH}")

tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, trust_remote_code=True)
if tokenizer.pad_token is None:
    tokenizer.pad_token = tokenizer.eos_token

model = AutoModelForCausalLM.from_pretrained(
    MODEL_PATH,
    torch_dtype=torch.bfloat16,
    device_map="auto",
    trust_remote_code=True
)

print(f"âœ… Model loaded")
print(f"  Parameters: {sum(p.numel() for p in model.parameters()) / 1e9:.2f}B")

# ============================================
# LoRA ì„¤ì •
# ============================================
print(f"\nğŸ”§ LoRA ì„¤ì •...")

lora_config = LoraConfig(
    task_type=TaskType.CAUSAL_LM,
    r=16,
    lora_alpha=32,
    lora_dropout=0.05,
    target_modules=["q_proj", "k_proj", "v_proj", "o_proj",
                    "gate_proj", "up_proj", "down_proj"],
    bias="none"
)

model = get_peft_model(model, lora_config)
trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
all_params = sum(p.numel() for p in model.parameters())

print(f"âœ… LoRA ì ìš© ì™„ë£Œ")
print(f"  Trainable: {trainable_params / 1e6:.2f}M ({100 * trainable_params / all_params:.2f}%)")

# ============================================
# ë°ì´í„° ë¡œë“œ
# ============================================
print(f"\nğŸ“‚ ë°ì´í„° ë¡œë“œ...")

train_file = DATA_PATH / "train.jsonl"
val_file = DATA_PATH / "val.jsonl"

train_dataset = HIRADataset(train_file, tokenizer, config['max_length'])
val_dataset = HIRADataset(val_file, tokenizer, config['max_length'])

train_loader = DataLoader(
    train_dataset,
    batch_size=config['batch_size'],
    shuffle=True,
    num_workers=0
)

val_loader = DataLoader(
    val_dataset,
    batch_size=config['batch_size'],
    shuffle=False,
    num_workers=0
)

# ============================================
# Optimizer & Scheduler
# ============================================
optimizer = torch.optim.AdamW(
    model.parameters(),
    lr=config['learning_rate'],
    weight_decay=0.01
)

total_steps = len(train_loader) * config['num_epochs'] // config['gradient_accumulation_steps']
scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
    optimizer,
    T_max=total_steps,
    eta_min=config['learning_rate'] * 0.1
)

# ============================================
# í•™ìŠµ ë£¨í”„
# ============================================
print(f"\nğŸš€ í•™ìŠµ ì‹œì‘...\n")

model.train()
global_step = 0
best_val_loss = float('inf')
patience_counter = 0

history = {
    'train_loss': [],
    'val_loss': [],
    'learning_rate': [],
    'best_epoch': 0
}

for epoch in range(config['num_epochs']):
    epoch_loss = 0
    progress_bar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{config['num_epochs']}")
    
    for step, batch in enumerate(progress_bar):
        # Forward
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        
        outputs = model(
            input_ids=input_ids,
            attention_mask=attention_mask,
            labels=labels
        )
        
        loss = outputs.loss / config['gradient_accumulation_steps']
        loss.backward()
        
        # Gradient accumulation
        if (step + 1) % config['gradient_accumulation_steps'] == 0:
            torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)
            optimizer.step()
            scheduler.step()
            optimizer.zero_grad()
            global_step += 1
            
            # Logging
            if global_step % config['logging_steps'] == 0:
                current_lr = scheduler.get_last_lr()[0]
                current_loss = loss.item() * config['gradient_accumulation_steps']
                
                history['train_loss'].append(current_loss)
                history['learning_rate'].append(current_lr)
                
                progress_bar.set_postfix({
                    'loss': f"{current_loss:.4f}",
                    'lr': f"{current_lr:.2e}"
                })
        
        epoch_loss += loss.item()
    
    # Epoch ì¢…ë£Œ - Training Loss
    avg_train_loss = epoch_loss / len(train_loader) * config['gradient_accumulation_steps']
    
    # Validation
    print(f"\nğŸ“Š Epoch {epoch+1} í‰ê°€ ì¤‘...")
    val_loss = evaluate(model, val_loader, device)
    history['val_loss'].append(val_loss)
    
    print(f"  Train Loss: {avg_train_loss:.4f}")
    print(f"  Val Loss:   {val_loss:.4f}")
    
    # Best model ì €ì¥
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        patience_counter = 0
        history['best_epoch'] = epoch + 1
        
        checkpoint_path = OUTPUT_PATH / "best_model"
        model.save_pretrained(checkpoint_path)
        tokenizer.save_pretrained(checkpoint_path)
        
        print(f"  âœ… Best model saved (Val Loss: {val_loss:.4f})")
    else:
        patience_counter += 1
        print(f"  âš ï¸  No improvement. Patience: {patience_counter}/{config['patience']}")
        
        if patience_counter >= config['patience']:
            print(f"\nğŸ›‘ Early stopping triggered at epoch {epoch+1}")
            print(f"   Best Val Loss: {best_val_loss:.4f} at epoch {history['best_epoch']}")
            break
    
    print()

# ============================================
# ìµœì¢… ì €ì¥
# ============================================
final_path = OUTPUT_PATH / "final_model"
model.save_pretrained(final_path)
tokenizer.save_pretrained(final_path)

# íˆìŠ¤í† ë¦¬ ì €ì¥
history_file = OUTPUT_PATH / "training_history.json"
with open(history_file, 'w') as f:
    json.dump(history, f, indent=2)

# ë¡œê·¸ ì €ì¥
log_file = OUTPUT_PATH / "training_log.txt"
with open(log_file, 'w') as f:
    f.write("="*80 + "\n")
    f.write("Training Summary\n")
    f.write("="*80 + "\n\n")
    f.write(f"Best Epoch: {history['best_epoch']}\n")
    f.write(f"Best Val Loss: {best_val_loss:.4f}\n")
    f.write(f"Final Train Loss: {avg_train_loss:.4f}\n")
    f.write(f"\nConfig:\n")
    for k, v in config.items():
        f.write(f"  {k}: {v}\n")

print("="*80)
print("âœ… í•™ìŠµ ì™„ë£Œ!")
print(f"  Best Val Loss: {best_val_loss:.4f}")
print(f"  Best Epoch: {history['best_epoch']}")
print(f"  Model: {final_path}")
print(f"  History: {history_file}")
print(f"  Log: {log_file}")
print("="*80)
