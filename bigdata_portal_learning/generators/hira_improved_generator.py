#!/usr/bin/env python3
"""
HIRA ê°œì„ ëœ í•™ìŠµ ë°ì´í„° ìƒì„±ê¸°
- ì¤‘ë³µ ì ‘ë‘ì‚¬/ì ‘ë¯¸ì‚¬ ì œê±°
- ìì—°ìŠ¤ëŸ¬ìš´ ë³€í˜•ë§Œ ìƒì„±
- ëª©í‘œ: 3,000-5,000ê±´
"""

import yaml
import json
import random
import re
from pathlib import Path
from typing import List, Dict
from collections import Counter

class HIRAImprovedGenerator:
    def __init__(self, core_qa_path: str):
        """ì´ˆê¸°í™”"""
        with open(core_qa_path, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f)

        self.core_qa = data['core_qa']
        self.training_data = []

        # ë™ì˜ì–´ ì‚¬ì „ (í™•ì¥)
        self.synonyms = {
            'ì‹ ì²­': ['ìš”ì²­', 'ë“±ë¡', 'ì ‘ìˆ˜'],
            'ë°©ë²•': ['ì ˆì°¨', 'ê³¼ì •', 'í”„ë¡œì„¸ìŠ¤'],
            'í™•ì¸': ['ì¡°íšŒ', 'ê²€ìƒ‰', 'ì°¾ê¸°', 'ë³´ê¸°'],
            'ê°€ëŠ¥': ['ë˜ë‚˜ìš”', 'í•  ìˆ˜ ìˆë‚˜ìš”'],
            'ì–´ë””ì„œ': ['ì–´ëŠ ê³³ì—ì„œ', 'ì–´ëŠ ë©”ë‰´ì—ì„œ', 'ì–´ë””ì—ì„œ'],
            'ì–´ë–»ê²Œ': ['ì–´ë–¤ ë°©ë²•ìœ¼ë¡œ', 'ì–´ë–¤ ì‹ìœ¼ë¡œ', 'ì–´ë–»ê²Œ'],
            'ë¬´ì—‡': ['ë­', 'ì–´ë–¤ ê²ƒ'],
            'ë°ì´í„°': ['ìë£Œ', 'ì •ë³´'],
            'ë¶„ì„': ['ì—°êµ¬', 'ë¶„ì„'],
            'í†µê³„': ['ìˆ˜ì¹˜', 'í†µê³„'],
            'ì œê³µ': ['ì œê³µ', 'ì§€ì›', 'ì œì‹œ'],
            'ì‚¬ìš©': ['ì´ìš©', 'í™œìš©'],
            'ë‹¤ìš´ë¡œë“œ': ['ë‚´ë ¤ë°›ê¸°', 'ë°›ê¸°'],
            'ì—…ë¡œë“œ': ['ì˜¬ë¦¬ê¸°', 'ì—…ë¡œë“œ'],
            'ë³€ê²½': ['ìˆ˜ì •', 'ë³€ê²½', 'í¸ì§‘'],
            'ì‚­ì œ': ['ì œê±°', 'ì‚­ì œ'],
            'ë¹„ìš©': ['ê¸ˆì•¡', 'ìš”ê¸ˆ', 'ë¹„ìš©'],
            'ë¬´ë£Œ': ['ê³µì§œ', 'ë¬´ë£Œ'],
            'í¬í•¨': ['í¬í•¨', 'ë‹´ê¸°'],
        }

    def generate(self, target_count: int = 8000):
        """í•™ìŠµ ë°ì´í„° ìƒì„±"""

        print("="*80)
        print("HIRA ê°œì„ ëœ í•™ìŠµ ë°ì´í„° ìƒì„±")
        print("="*80)
        print(f"ëª©í‘œ: {target_count:,}ê±´\n")

        # 1. í•µì‹¬ Q&A ì¹´ìš´íŠ¸
        core_count = sum(len(items) for items in self.core_qa.values())
        print(f"í•µì‹¬ Q&A: {core_count}ê°œ")

        # 2. ê° Q&Aë‹¹ ìƒì„±í•  ë³€í˜• ìˆ˜
        variants_per_qa = (target_count - core_count) // core_count
        print(f"ê° Q&Aë‹¹ ì•½ {variants_per_qa}ê°œ ë³€í˜• ìƒì„±\n")

        # 3. ì›ë³¸ ì¶”ê°€
        for menu, items in self.core_qa.items():
            for item in items:
                question = item['q']
                answer = item['a']
                self.training_data.append({
                    "instruction": question,
                    "input": "",
                    "output": answer
                })

        # 4. ë³€í˜• ìƒì„±
        for menu, items in self.core_qa.items():
            for item in items:
                original_q = item['q']
                answer = item['a']

                # ê° Q&Aì— ëŒ€í•´ variants_per_qaê°œ ë³€í˜• ìƒì„±
                generated = 0
                attempts = 0
                max_attempts = variants_per_qa * 5  # ì‹œë„ íšŸìˆ˜ ì¦ê°€

                while generated < variants_per_qa and attempts < max_attempts:
                    variant = self._generate_natural_variant(original_q)

                    if variant and variant != original_q:
                        # ì˜¤íƒ€/ë§ì¶¤ë²• ê²€ì¦
                        variant = self._fix_typos(variant)

                        # ì¤‘ë³µ ì²´í¬
                        if not any(item['instruction'] == variant for item in self.training_data):
                            self.training_data.append({
                                "instruction": variant,
                                "input": "",
                                "output": answer
                            })
                            generated += 1

                    attempts += 1

        print(f"{'='*80}")
        print(f"âœ… ìƒì„± ì™„ë£Œ: {len(self.training_data):,}ê±´")
        print(f"{'='*80}\n")

        return self.training_data

    def _generate_natural_variant(self, original_q: str) -> str:
        """ìì—°ìŠ¤ëŸ¬ìš´ ë³€í˜• ìƒì„± (í’ˆì§ˆ ìš°ì„ )"""

        variants = []

        # 1. ì–´ë¯¸ ë³€í˜• (8íšŒ)
        for _ in range(8):
            variants.extend(self._ë³€í˜•_ì–´ë¯¸(original_q))

        # 2. ì§ˆë¬¸ í˜•ì‹ ë³€í˜• (8íšŒ)
        for _ in range(8):
            variants.extend(self._ë³€í˜•_ì§ˆë¬¸í˜•ì‹(original_q))

        # 3. ë™ì˜ì–´ ì¹˜í™˜ (8íšŒ)
        for _ in range(8):
            variants.extend(self._ë³€í˜•_ë™ì˜ì–´(original_q))

        # 4. ì¡°ì‚¬ ë³€í˜• (8íšŒ)
        for _ in range(8):
            variants.extend(self._ë³€í˜•_ì¡°ì‚¬(original_q))

        # 5. ì¶•ì•½/í™•ì¥ (8íšŒ)
        for _ in range(8):
            variants.extend(self._ë³€í˜•_ì¶•ì•½í™•ì¥(original_q))

        # 6. ì˜ë¬¸ì‚¬ ë³€í˜• (8íšŒ)
        for _ in range(8):
            variants.extend(self._ë³€í˜•_ì˜ë¬¸ì‚¬(original_q))

        # ì¤‘ë³µ ì œê±°
        unique_variants = list(set(variants))

        # ì›ë³¸ ì œì™¸
        valid_variants = [v for v in unique_variants if v != original_q and len(v) >= 5 and len(v) <= 100]

        if valid_variants:
            return random.choice(valid_variants)
        else:
            return None

    def _ë³€í˜•_ì–´ë¯¸(self, question: str) -> List[str]:
        """ì–´ë¯¸ ë³€í˜• (ì¡´ëŒ“ë§/ë°˜ë§) - ëœë¤í™”"""
        variants = []

        patterns = [
            (r'(.+)í•˜ë‚˜ìš”\?', [r'\1í•´ìš”?', r'\1í• ê¹Œìš”?', r'\1í•˜ì£ ?', r'\1í•©ë‹ˆê¹Œ?']),
            (r'(.+)ì¸ê°€ìš”\?', [r'\1ì´ì—ìš”?', r'\1ì¼ê¹Œìš”?', r'\1ì´ì£ ?', r'\1ì…ë‹ˆê¹Œ?']),
            (r'(.+)ìˆë‚˜ìš”\?', [r'\1ìˆì–´ìš”?', r'\1ìˆì„ê¹Œìš”?', r'\1ìˆì£ ?', r'\1ìˆìŠµë‹ˆê¹Œ?']),
            (r'(.+)ë˜ë‚˜ìš”\?', [r'\1ë¼ìš”?', r'\1ë ê¹Œìš”?', r'\1ë˜ì£ ?', r'\1ë©ë‹ˆê¹Œ?']),
            (r'(.+)ê°€ëŠ¥í•œê°€ìš”\?', [r'\1ê°€ëŠ¥í•´ìš”?', r'\1ê°€ëŠ¥í• ê¹Œìš”?', r'\1í•  ìˆ˜ ìˆë‚˜ìš”?', r'\1ê°€ëŠ¥í•©ë‹ˆê¹Œ?']),
            (r'(.+)ë­”ê°€ìš”\?', [r'\1ë­ì˜ˆìš”?', r'\1ë¬´ì—‡ì¸ê°€ìš”?', r'\1ë­ì£ ?', r'\1ë¬´ì—‡ì…ë‹ˆê¹Œ?']),
            (r'(.+)ì–´ë–»ê²Œ\?', [r'\1ì–´ë–¤ ë°©ë²•ìœ¼ë¡œ?', r'\1ì–´ë–¤ ì‹ìœ¼ë¡œ?', r'\1ì–´ë–»ê²Œ í•´ìš”?']),
            (r'(.+)ì–´ë””ì„œ\?', [r'\1ì–´ëŠ ê³³ì—ì„œ?', r'\1ì–´ë””ì—ì„œ?', r'\1ì–´ëŠ ë©”ë‰´ì—ì„œ?']),
            (r'(.+)ì™œ\?', [r'\1ì™œìš”?', r'\1ì´ìœ ê°€ ë­ì˜ˆìš”?', r'\1ì™œ ê·¸ëŸ°ê°€ìš”?']),
            (r'(.+)ì–¸ì œ\?', [r'\1ì–¸ì œìš”?', r'\1ì–¸ì œì¸ê°€ìš”?', r'\1ì‹œê¸°ëŠ”?']),
            (r'(.+)ì–¼ë§ˆ\?', [r'\1ì–¼ë§ˆì˜ˆìš”?', r'\1ì–¼ë§ˆì¸ê°€ìš”?', r'\1ë¹„ìš©ì€?']),
        ]

        for pattern, replacements in patterns:
            if re.search(pattern, question):
                # ëœë¤í•˜ê²Œ 1-2ê°œë§Œ ì„ íƒ
                selected = random.sample(replacements, k=min(2, len(replacements)))
                for repl in selected:
                    variant = re.sub(pattern, repl, question)
                    if variant != question:
                        variants.append(variant)

        return variants

    def _ë³€í˜•_ì§ˆë¬¸í˜•ì‹(self, question: str) -> List[str]:
        """ì§ˆë¬¸ í˜•ì‹ ë³€í˜•"""
        variants = []

        patterns = [
            (r'(.+) ì–´ë–»ê²Œ í•˜ë‚˜ìš”\?', [r'\1 ë°©ë²•ì€?', r'\1 ë°©ë²•ì´ ì–´ë–»ê²Œ ë˜ë‚˜ìš”?', r'\1 ì–´ë–¤ ì‹ìœ¼ë¡œ í•˜ë‚˜ìš”?']),
            (r'(.+) ë­”ê°€ìš”\?', [r'\1ì´ ë¬´ì—‡ì¸ê°€ìš”?', r'\1ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”', r'\1 ì„¤ëª…í•´ì£¼ì„¸ìš”', r'\1ì€ ë­”ê°€ìš”?']),
            (r'(.+) ì–´ë””ì„œ (.+)\?', [r'\2 ì–´ë””ì—ì„œ í•˜ë‚˜ìš”?', r'\2 ì–´ëŠ ê³³ì—ì„œ í•˜ë‚˜ìš”?', r'\1 ì–´ë””ì„œ \2?']),
            (r'(.+) ê°€ëŠ¥í•œê°€ìš”\?', [r'\1 ìˆ˜ ìˆë‚˜ìš”?', r'\1 ë˜ë‚˜ìš”?', r'\1 í•  ìˆ˜ ìˆë‚˜ìš”?']),
            (r'(.+)ì€ ë¬´ì—‡ì¸ê°€ìš”\?', [r'\1ì´ ë­”ê°€ìš”?', r'\1ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”', r'\1ì„ ì•Œë ¤ì£¼ì„¸ìš”']),
            (r'(.+)ë¥¼ ì–´ë–»ê²Œ\?', [r'\1 ì–´ë–»ê²Œ í•˜ë‚˜ìš”?', r'\1 ë°©ë²•ì€?', r'\1 ì–´ë–¤ ì‹ìœ¼ë¡œ í•˜ë‚˜ìš”?']),
            (r'(.+)ì´ ìˆë‚˜ìš”\?', [r'\1 ìˆì–´ìš”?', r'\1ì´ ì œê³µë˜ë‚˜ìš”?', r'\1 í™•ì¸í•  ìˆ˜ ìˆë‚˜ìš”?']),
        ]

        for pattern, replacements in patterns:
            if re.search(pattern, question):
                for repl in replacements:
                    variant = re.sub(pattern, repl, question)
                    if variant != question:
                        variants.append(variant)

        return variants

    def _ë³€í˜•_ë™ì˜ì–´(self, question: str) -> List[str]:
        """ë™ì˜ì–´ ì¹˜í™˜ - ëœë¤í™”"""
        variants = []

        # ì§ˆë¬¸ì— ìˆëŠ” ë‹¨ì–´ ì°¾ê¸°
        matching_words = [word for word in self.synonyms.keys() if word in question]

        # ëœë¤í•˜ê²Œ 1-2ê°œ ë‹¨ì–´ë§Œ ì„ íƒ
        if matching_words:
            selected_words = random.sample(matching_words, k=min(2, len(matching_words)))

            for word in selected_words:
                synonyms = self.synonyms[word]
                # ê° ë‹¨ì–´ë‹¹ ëœë¤í•˜ê²Œ 1ê°œ ë™ì˜ì–´ë§Œ ì„ íƒ
                synonym = random.choice(synonyms)
                variant = question.replace(word, synonym)
                if variant != question:
                    variants.append(variant)

        return variants

    def _ë³€í˜•_ì¡°ì‚¬(self, question: str) -> List[str]:
        """ì¡°ì‚¬ ë³€í˜•"""
        variants = []

        replacements = [
            ('ì€', 'ëŠ”'),
            ('ì´', 'ê°€'),
            ('ì„', 'ë¥¼'),
            ('ê³¼', 'ì™€'),
        ]

        for old, new in replacements:
            if old in question:
                variant = question.replace(old, new, 1)
                variants.append(variant)

        return variants

    def _ë³€í˜•_ì¶•ì•½í™•ì¥(self, question: str) -> List[str]:
        """ì¶•ì•½ ë˜ëŠ” í™•ì¥"""
        variants = []

        # ì¶•ì•½
        abbr_patterns = [
            (r'(.+) ì–´ë–»ê²Œ (.+)\?', r'\1 \2?'),
            (r'(.+) ì–´ë–¤ (.+)\?', r'\1 \2?'),
        ]

        for pattern, replacement in abbr_patterns:
            if re.match(pattern, question):
                variant = re.sub(pattern, replacement, question)
                if variant != question:
                    variants.append(variant)

        # í™•ì¥
        if not question.endswith('?'):
            variants.append(question + '?')

        return variants

    def _ë³€í˜•_ë‹¨ì–´ìˆœì„œ(self, question: str) -> List[str]:
        """ë‹¨ì–´ ìˆœì„œ ë³€ê²½"""
        variants = []

        # ê°„ë‹¨í•œ ìˆœì„œ ë³€ê²½ íŒ¨í„´
        patterns = [
            (r'(.+) ì–´ë””ì„œ (.+)', r'\2 ì–´ë””ì„œ í•˜ë‚˜ìš”?'),
            (r'(.+)ì€ (.+)', r'\2 \1ì€?'),
            (r'(.+)ì™€ (.+) ì°¨ì´', r'\2ì™€ \1 ì°¨ì´'),
        ]

        for pattern, replacement in patterns:
            if re.search(pattern, question):
                variant = re.sub(pattern, replacement, question)
                if variant != question:
                    variants.append(variant)

        return variants

    def _ë³€í˜•_ì˜ë¬¸ì‚¬(self, question: str) -> List[str]:
        """ì˜ë¬¸ì‚¬ ë³€í˜•"""
        variants = []

        replacements = [
            ('ë­”ê°€ìš”', 'ë¬´ì—‡ì¸ê°€ìš”'),
            ('ë¬´ì—‡ì¸ê°€ìš”', 'ë­”ê°€ìš”'),
            ('ì–´ë–»ê²Œ', 'ì–´ë–¤ ë°©ë²•ìœ¼ë¡œ'),
            ('ì–´ë–¤ ë°©ë²•ìœ¼ë¡œ', 'ì–´ë–»ê²Œ'),
            ('ì–´ë””ì„œ', 'ì–´ëŠ ê³³ì—ì„œ'),
            ('ì–´ëŠ ê³³ì—ì„œ', 'ì–´ë””ì„œ'),
            ('ì–¸ì œ', 'ëª‡ ì‹œì—'),
            ('ì™œ', 'ì–´ë–¤ ì´ìœ ë¡œ'),
        ]

        for old, new in replacements:
            if old in question:
                variant = question.replace(old, new)
                if variant != question:
                    variants.append(variant)

        return variants

    def _is_valid_variant(self, text: str) -> bool:
        """ë³€í˜• í’ˆì§ˆ ê²€ì¦"""

        # ìµœì†Œ ê¸¸ì´
        if len(text) < 5:
            return False

        # ìµœëŒ€ ê¸¸ì´ (ë„ˆë¬´ ê¸´ ê²ƒ ì œì™¸)
        if len(text) > 100:
            return False

        # ì¤‘ë³µ ì¡°ì‚¬ íŒ¨í„´ ì²´í¬
        invalid_patterns = [
            r'([ê°€-í£])(ëŠ”|ì€|ì„|ë¥¼|ì´|ê°€)(ëŠ”|ì€|ì„|ë¥¼|ì´|ê°€)',  # ì¤‘ë³µ ì¡°ì‚¬
            r'([ê°€-í£]) (ëŠ”|ì€|ì„|ë¥¼|ì´|ê°€)',  # ì¡°ì‚¬ ì• ê³µë°±
            r'(ìˆ˜|í• |ë |ë°›|ë³¼) (ìˆ˜|í• |ë |ë°›|ë³¼)',  # ì¤‘ë³µ ë™ì‚¬
            r'ì–´ë–»ê²Œ ì–´ë–»ê²Œ',  # ì¤‘ë³µ ì˜ë¬¸ì‚¬
            r'ë­”ê°€ìš” ë­”ê°€ìš”',
            r'ìˆë‚˜ìš” ìˆë‚˜ìš”',
        ]

        for pattern in invalid_patterns:
            if re.search(pattern, text):
                return False

        # í•„ìˆ˜ ì¢…ê²°ì–´ë¯¸ ì²´í¬ (ì§ˆë¬¸ì´ë¯€ë¡œ) - í™•ì¥
        valid_endings = [
            '?', 'ìš”?', 'ì£ ?', 'ë‚˜ìš”?', 'ê¹Œìš”?', 'í•´ìš”?', 'ê°€ìš”?',
            'ìš”', 'ì£ ', 'ë‚˜ìš”', 'ê¹Œìš”', 'í•´ìš”', 'ê°€ìš”', 'ì˜ˆìš”', 'ì„¸ìš”',
            'ëŠ”ìš”', 'ì—ìš”', 'ì–´ìš”', 'ì—¬ìš”', 'ë˜ìš”', 'ëŒ€ìš”',
            'ì¸ê°€ìš”', 'ì¸ê°€ìš”?', 'ìŠµë‹ˆê¹Œ', 'ìŠµë‹ˆê¹Œ?', 'ì…ë‹ˆê¹Œ', 'ì…ë‹ˆê¹Œ?',
            'ë ê¹Œìš”', 'ë ê¹Œìš”?', 'í• ê¹Œìš”', 'í• ê¹Œìš”?',
            'ì¡°íšŒ', 'ì‹ ì²­', 'ë°©ë²•', 'ì ˆì°¨', 'í™•ì¸', 'ê²€ìƒ‰',
            'ìˆë‚˜ìš”', 'ìˆë‚˜ìš”?', 'ìˆì–´ìš”', 'ìˆì–´ìš”?',
            'ë˜ë‚˜ìš”', 'ë˜ë‚˜ìš”?', 'ë¼ìš”', 'ë¼ìš”?',
            'ë­ì£ ', 'ë­ì£ ?', 'ë­”ê°€ìš”', 'ë­”ê°€ìš”?', 'ë¬´ì—‡ì¸ê°€ìš”', 'ë¬´ì—‡ì¸ê°€ìš”?',
        ]
        if not any(text.endswith(e) for e in valid_endings):
            return False

        return True

    def _fix_typos(self, text: str) -> str:
        """ì˜¤íƒ€/ë§ì¶¤ë²• ìˆ˜ì • (ê°•í™” ë²„ì „)"""

        # ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤íƒ€ íŒ¨í„´
        typo_fixes = [
            # ë°ì´í„° ê´€ë ¨
            ('ë°ê°€í„°', 'ë°ì´í„°'),
            ('ë°ì´ê°€', 'ë°ì´í„°'),
            ('ìë£Œ', 'ìë£Œ'),  # íŒ¨í„´ ìœ ì§€

            # ì¡°ì‚¬ ì˜¤ë¥˜ - ë°›ì¹¨ ìˆëŠ” ë‹¨ì–´
            ('ê¸°ê°„ëŠ”', 'ê¸°ê°„ì€'),
            ('ë°©ë²•ëŠ”', 'ë°©ë²•ì€'),
            ('ëª©ë¡ëŠ”', 'ëª©ë¡ì€'),
            ('í†µê³„ëŠ”', 'í†µê³„ëŠ”'),
            ('ì •ë³´ëŠ”', 'ì •ë³´ëŠ”'),
            ('ê³µì§€ì‚¬í•­ëŠ”', 'ê³µì§€ì‚¬í•­ì€'),
            ('ë°ì´í„°ì…‹ëŠ”', 'ë°ì´í„°ì…‹ì€'),
            ('ì½”ë“œëŠ”', 'ì½”ë“œëŠ”'),  # íŒ¨í„´ ìœ ì§€
            ('ì œí•œëŠ”', 'ì œí•œì€'),
            ('ìš©ëŸ‰ëŠ”', 'ìš©ëŸ‰ì€'),
            ('íŒŒì¼ëŠ”', 'íŒŒì¼ì€'),
            ('ì•½ê´€ëŠ”', 'ì•½ê´€ì€'),
            ('ì§ˆë¬¸ëŠ”', 'ì§ˆë¬¸ì€'),
            ('ì´ìš©ëŠ”', 'ì´ìš©ì€'),
            ('ì‚¬ìš©ëŠ”', 'ì‚¬ìš©ì€'),

            # ë™ì‚¬ ì˜¤ë¥˜
            ('ë°›ë¥¼', 'ë°›ì„'),
            ('ì‚¬ìš©ë¥¼', 'ì‚¬ìš©ì„'),
            ('ì´ìš©ë¥¼', 'ì´ìš©ì„'),
            ('í™•ì¸ë¥¼', 'í™•ì¸ì„'),
            ('í• ë¥¼', 'í• '),
            ('ë ë¥¼', 'ë '),
            ('ìˆ˜ ìˆë¥¼', 'ìˆ˜ ìˆì„'),
            ('ì™€ì œ', 'ê³¼ì œ'),
            ('ê°€ìš©', 'ì´ìš©'),
            ('ìˆ˜ ìˆë¥¼ê¹Œìš”', 'ìˆ˜ ìˆì„ê¹Œìš”'),

            # ê³µë°± ì˜¤ë¥˜
            (' ëŠ”', 'ëŠ”'),
            (' ì€', 'ì€'),
            (' ì„', 'ì„'),
            (' ë¥¼', 'ë¥¼'),
            (' ì´', 'ì´'),
            (' ê°€', 'ê°€'),
            ('  ', ' '),  # ì¤‘ë³µ ê³µë°±

            # ì˜ë¬¸ì‚¬ ì˜¤ë¥˜
            ('ëˆ„ê°€ì´ìš©', 'ëˆ„ê°€ ì´ìš©'),
            ('ì–´ë””ì„œê²€ìƒ‰', 'ì–´ë””ì„œ ê²€ìƒ‰'),
            ('ì–´ë–»ê²Œí•´ìš”', 'ì–´ë–»ê²Œ í•´ìš”'),
        ]

        for wrong, correct in typo_fixes:
            text = text.replace(wrong, correct)

        # ì •ê·œì‹ ê¸°ë°˜ ì¡°ì‚¬ ì˜¤ë¥˜ ìˆ˜ì •
        text = re.sub(r'([ê°€-í£])ëŠ”ëŠ”', r'\1ëŠ”', text)
        text = re.sub(r'([ê°€-í£])ì€ì€', r'\1ì€', text)
        text = re.sub(r'([ê°€-í£])ì„ì„', r'\1ì„', text)
        text = re.sub(r'([ê°€-í£])ë¥¼ë¥¼', r'\1ë¥¼', text)
        text = re.sub(r'([ê°€-í£])ì´ì´', r'\1ì´', text)
        text = re.sub(r'([ê°€-í£])ê°€ê°€', r'\1ê°€', text)

        # ë™ì‚¬ ì¤‘ë³µ ìˆ˜ì •
        text = re.sub(r'(í• |ë |ë°›|ë³¼) (í• |ë |ë°›|ë³¼)', r'\1', text)
        text = re.sub(r'ìˆ˜ ìˆë¥¼', 'ìˆ˜ ìˆì„', text)
        text = re.sub(r'ìˆ˜ ìˆì„ë¥¼', 'ìˆ˜ ìˆì„', text)

        # ëª…ì‚¬+ì¡°ì‚¬ ë¶™ì–´ì“°ê¸° ìˆ˜ì • (ì€/ëŠ”)
        text = re.sub(r'([ê°€-í£]{2,})ì€([ê°€-í£])', lambda m: m.group(1) + 'ì€ ' + m.group(2) if m.group(2) in 'ê°€ë‚˜ë‹¤ë¼ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€íŒŒí•˜' else m.group(0), text)
        text = re.sub(r'([ê°€-í£]{2,})ëŠ”([ê°€-í£])', lambda m: m.group(1) + 'ëŠ” ' + m.group(2) if m.group(2) in 'ê°€ë‚˜ë‹¤ë¼ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€íŒŒí•˜' else m.group(0), text)

        # í”í•œ ë¶™ì–´ì“°ê¸° ì˜¤ë¥˜
        text = re.sub(r'ë§¤ì¹­ì€ê°€ëŠ¥', 'ë§¤ì¹­ì€ ê°€ëŠ¥', text)
        text = re.sub(r'ì‚¬ìš©ì€ìˆ˜', 'ì‚¬ìš©ì€ ìˆ˜', text)
        text = re.sub(r'ì´ìš©ì€ê°€ëŠ¥', 'ì´ìš©ì€ ê°€ëŠ¥', text)
        text = re.sub(r'ì‹ ì²­ì€ì–´ë–»ê²Œ', 'ì‹ ì²­ì€ ì–´ë–»ê²Œ', text)

        return text

    def get_statistics(self) -> Dict:
        """í†µê³„ ì •ë³´"""
        questions = [item['instruction'] for item in self.training_data]
        answers = [item['output'] for item in self.training_data]

        q_lengths = [len(q) for q in questions]
        a_lengths = [len(a) for a in answers]

        # ì§ˆë¬¸ ì‹œì‘ íŒ¨í„´
        start_patterns = Counter()
        for q in questions:
            words = q.split()[:2]
            pattern = ' '.join(words) if len(words) >= 2 else q[:10]
            start_patterns[pattern] += 1

        return {
            "total": len(self.training_data),
            "q_length_avg": sum(q_lengths) / len(q_lengths),
            "q_length_min": min(q_lengths),
            "q_length_max": max(q_lengths),
            "a_length_avg": sum(a_lengths) / len(a_lengths),
            "a_length_min": min(a_lengths),
            "a_length_max": max(a_lengths),
            "start_patterns": start_patterns.most_common(10),
        }

    def save_jsonl(self, output_path: str):
        """JSONL ì €ì¥"""
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            for item in self.training_data:
                f.write(json.dumps(item, ensure_ascii=False) + '\n')

        print(f"âœ… JSONL ì €ì¥ ì™„ë£Œ: {output_path}")
        print(f"   ì´ {len(self.training_data):,}ê±´\n")

    def save_json(self, output_path: str):
        """JSON ì €ì¥"""
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.training_data, f, ensure_ascii=False, indent=2)

        print(f"âœ… JSON ì €ì¥ ì™„ë£Œ: {output_path}\n")

    def print_samples(self, count: int = 10):
        """ìƒ˜í”Œ ì¶œë ¥"""
        print(f"{'='*80}")
        print(f"ğŸ“ ë¬´ì‘ìœ„ ìƒ˜í”Œ {count}ê°œ")
        print(f"{'='*80}\n")

        samples = random.sample(self.training_data, min(count, len(self.training_data)))

        for i, sample in enumerate(samples, 1):
            print(f"[ìƒ˜í”Œ {i}]")
            print(f"Q: {sample['instruction']}")
            print(f"A: {sample['output'][:80]}...\n")

    def print_statistics(self):
        """í†µê³„ ì¶œë ¥"""
        stats = self.get_statistics()

        print(f"{'='*80}")
        print(f"ğŸ“Š ë°ì´í„° í†µê³„")
        print(f"{'='*80}\n")

        print(f"[ì§ˆë¬¸ ê¸¸ì´]")
        print(f"  í‰ê· : {stats['q_length_avg']:.1f}ì")
        print(f"  ìµœì†Œ: {stats['q_length_min']}ì")
        print(f"  ìµœëŒ€: {stats['q_length_max']}ì\n")

        print(f"[ë‹µë³€ ê¸¸ì´]")
        print(f"  í‰ê· : {stats['a_length_avg']:.1f}ì")
        print(f"  ìµœì†Œ: {stats['a_length_min']}ì")
        print(f"  ìµœëŒ€: {stats['a_length_max']}ì\n")

        print(f"[ì§ˆë¬¸ ì‹œì‘ íŒ¨í„´ TOP 10]")
        for i, (pattern, count) in enumerate(stats['start_patterns'], 1):
            pct = (count / stats['total']) * 100
            print(f"  {i:2d}. {pattern:30s}: {count:4,}ê±´ ({pct:4.1f}%)")


def main():
    # ê²½ë¡œ ì„¤ì •
    core_qa_path = "/home/user/bigdataptAI/bigdata_portal_learning/config/hira_core_qa_expanded.yaml"
    output_jsonl = "/home/user/bigdataptAI/bigdata_portal_learning/output/hira_train_final.jsonl"
    output_json = "/home/user/bigdataptAI/bigdata_portal_learning/output/hira_train_final.json"

    # ìƒì„±ê¸° ì´ˆê¸°í™”
    generator = HIRAImprovedGenerator(core_qa_path)

    # ë°ì´í„° ìƒì„± (ëª©í‘œ: 3,000ê±´ - í˜„ì‹¤ì  ëª©í‘œ)
    generator.generate(target_count=3000)

    # í†µê³„ ì¶œë ¥
    generator.print_statistics()

    # ìƒ˜í”Œ ì¶œë ¥
    generator.print_samples(10)

    # ì €ì¥
    generator.save_jsonl(output_jsonl)
    generator.save_json(output_json)

    print(f"{'='*80}")
    print(f"âœ… ê°œì„ ëœ ë°ì´í„° ìƒì„± ì™„ë£Œ!")
    print(f"{'='*80}\n")

    print(f"ğŸ“ ìƒì„± íŒŒì¼:")
    print(f"  1. {output_jsonl} (í•™ìŠµìš©)")
    print(f"  2. {output_json} (ê²€í† ìš©)\n")


if __name__ == "__main__":
    main()
