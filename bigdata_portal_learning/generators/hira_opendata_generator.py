#!/usr/bin/env python3
"""
HIRA ì˜¤í”ˆë°ì´í„° í¬í„¸ í•™ìŠµ ë°ì´í„° ìƒì„±ê¸°
- ì£¼ì œë³„ 3,000ê°œ ì§ˆì˜ì‘ë‹µ ì„¸íŠ¸ ìƒì„± ëª©í‘œ
- í…œí”Œë¦¿ ê¸°ë°˜ + ê³ ê¸‰ ë³€í˜• ê¸°ë²•
"""

import yaml
import json
import random
import re
from pathlib import Path
from typing import List, Dict
from collections import Counter

class HIRAOpenDataGenerator:
    def __init__(self, structure_path: str):
        """ì´ˆê¸°í™”"""
        with open(structure_path, 'r', encoding='utf-8') as f:
            data = yaml.safe_load(f)

        self.menus = data['menus']
        self.training_data = []

        # í™•ì¥ëœ ë™ì˜ì–´ ì‚¬ì „
        self.synonyms = {
            'ì‹ ì²­': ['ìš”ì²­', 'ë“±ë¡', 'ì œì¶œ', 'ì ‘ìˆ˜'],
            'ë°©ë²•': ['ì ˆì°¨', 'ê³¼ì •', 'í”„ë¡œì„¸ìŠ¤', 'ìˆœì„œ'],
            'í™•ì¸': ['ì¡°íšŒ', 'ê²€ìƒ‰', 'ì°¾ê¸°', 'ì°¾ì•„ë³´ê¸°'],
            'ê°€ëŠ¥': ['ë˜ë‚˜ìš”', 'í•  ìˆ˜ ìˆë‚˜ìš”', 'ê°€ëŠ¥í•œê°€ìš”', 'ë˜ëŠ”ì§€'],
            'ì–´ë””ì„œ': ['ì–´ëŠ ê³³ì—ì„œ', 'ì–´ëŠ ë©”ë‰´ì—ì„œ', 'ì–´ë””ì—ì„œ', 'ì–´ëŠ ê³³'],
            'ì–´ë–»ê²Œ': ['ì–´ë–¤ ë°©ë²•ìœ¼ë¡œ', 'ì–´ë–¤ ì‹ìœ¼ë¡œ', 'ì–´ë–»ê²Œ í•˜ë©´', 'ë°©ë²•'],
            'ë¬´ì—‡': ['ë­', 'ì–´ë–¤ ê²ƒ', 'ë¬´ìŠ¨'],
            'ë°ì´í„°': ['ìë£Œ', 'ì •ë³´'],
            'ë¶„ì„': ['ì—°êµ¬', 'ì¡°ì‚¬'],
            'í†µê³„': ['ìˆ˜ì¹˜', 'ì§€í‘œ'],
            'ì„œë¹„ìŠ¤': ['ê¸°ëŠ¥', 'ì œê³µ'],
            'ì´ìš©': ['ì‚¬ìš©', 'í™œìš©'],
            'ì œê³µ': ['ì§€ì›', 'ì œê³µ'],
            'ì—°êµ¬ì': ['ì—°êµ¬ì›', 'ë¶„ì„ê°€', 'í•™ì'],
            'í™˜ì': ['ìˆ˜ì§„ì', 'ì§„ë£Œí™˜ì'],
        }

        # ì§ˆë¬¸ ì ‘ë‘ì‚¬ ë³€í˜•
        self.question_prefixes = [
            '',
            'í˜¹ì‹œ ',
            'ì œê°€ ê¶ê¸ˆí•œê²Œ ',
            'ì•Œê³  ì‹¶ì€ë° ',
            'ë¬¸ì˜ë“œë¦½ë‹ˆë‹¤. ',
            'ì§ˆë¬¸ìˆì–´ìš”. ',
        ]

        # ì§ˆë¬¸ ì ‘ë¯¸ì‚¬ ë³€í˜•
        self.question_suffixes = [
            '',
            ' ì•Œë ¤ì£¼ì„¸ìš”',
            ' ì•Œë ¤ì¤˜',
            ' ì„¤ëª…í•´ì£¼ì„¸ìš”',
            ' ê¶ê¸ˆí•©ë‹ˆë‹¤',
            ' ê¶ê¸ˆí•´ìš”',
            ' ì¢€ ì•Œë ¤ì£¼ì‹¤ ìˆ˜ ìˆë‚˜ìš”',
        ]

    def generate(self, target_per_topic: int = 3000):
        """ì£¼ì œë³„ ë°ì´í„° ìƒì„±"""

        print("="*80)
        print("HIRA ì˜¤í”ˆë°ì´í„° í¬í„¸ í•™ìŠµ ë°ì´í„° ìƒì„±")
        print("="*80)
        print(f"ì£¼ì œë³„ ëª©í‘œ: {target_per_topic:,}ê±´\n")

        total_topics = sum(len(menu_data['topics']) for menu_data in self.menus.values())
        print(f"ì´ ì£¼ì œ ìˆ˜: {total_topics}ê°œ")
        print(f"ì˜ˆìƒ ì´ ë°ì´í„°: {total_topics * target_per_topic:,}ê±´\n")

        for menu_id, menu_data in self.menus.items():
            menu_name = menu_data['name']
            print(f"\n{'='*80}")
            print(f"ğŸ“ ë©”ë‰´: {menu_name}")
            print(f"{'='*80}")

            for topic in menu_data['topics']:
                topic_name = topic['name']
                core_qa = topic.get('core_qa', [])

                print(f"\n  ğŸ“Œ ì£¼ì œ: {topic_name}")
                print(f"     í•µì‹¬ Q&A: {len(core_qa)}ê°œ")

                if not core_qa:
                    print(f"     âš ï¸  í•µì‹¬ Q&Aê°€ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
                    continue

                # 1. ì›ë³¸ ì¶”ê°€
                for item in core_qa:
                    self.training_data.append({
                        "instruction": item['q'],
                        "input": "",
                        "output": item['a'],
                        "metadata": {
                            "menu": menu_id,
                            "menu_name": menu_name,
                            "topic": topic['id'],
                            "topic_name": topic_name,
                            "type": "original"
                        }
                    })

                # 2. ë³€í˜• ìƒì„±
                target_variants = target_per_topic - len(core_qa)
                variants_per_qa = target_variants // len(core_qa)

                print(f"     ê° Q&Aë‹¹ ì•½ {variants_per_qa}ê°œ ë³€í˜• ìƒì„± ì¤‘...")

                generated_count = 0
                for item in core_qa:
                    original_q = item['q']
                    answer = item['a']

                    # ê° Q&Aì— ëŒ€í•´ variants_per_qaê°œ ë³€í˜• ìƒì„±
                    for _ in range(variants_per_qa):
                        variant = self._generate_variant(original_q)

                        if variant and variant != original_q:
                            # ì¤‘ë³µ ì²´í¬
                            if not any(d['instruction'] == variant for d in self.training_data):
                                self.training_data.append({
                                    "instruction": variant,
                                    "input": "",
                                    "output": answer,
                                    "metadata": {
                                        "menu": menu_id,
                                        "menu_name": menu_name,
                                        "topic": topic['id'],
                                        "topic_name": topic_name,
                                        "type": "variant"
                                    }
                                })
                                generated_count += 1

                print(f"     âœ… ìƒì„± ì™„ë£Œ: {len(core_qa) + generated_count:,}ê±´")

        print(f"\n{'='*80}")
        print(f"âœ… ì „ì²´ ìƒì„± ì™„ë£Œ: {len(self.training_data):,}ê±´")
        print(f"{'='*80}\n")

        return self.training_data

    def _generate_variant(self, original_q: str) -> str:
        """ì§ˆë¬¸ ë³€í˜• ìƒì„± (ë‹¤ì–‘í•œ ê¸°ë²• ì ìš©)"""

        # ë³€í˜• ê¸°ë²• ë¦¬ìŠ¤íŠ¸
        techniques = [
            self._ë³€í˜•_ì–´ë¯¸,
            self._ë³€í˜•_ì§ˆë¬¸í˜•ì‹,
            self._ë³€í˜•_ë™ì˜ì–´,
            self._ë³€í˜•_ì¡°ì‚¬,
            self._ë³€í˜•_ì¶•ì•½í™•ì¥,
            self._ë³€í˜•_ë‹¨ì–´ìˆœì„œ,
            self._ë³€í˜•_ì˜ë¬¸ì‚¬,
            self._ë³€í˜•_ì ‘ë‘ì ‘ë¯¸ì‚¬,
            self._ë³€í˜•_ì¡´ëŒ“ë§ë°˜ë§,
            self._ë³€í˜•_ë¶€ê°€í‘œí˜„,
        ]

        # ëœë¤í•˜ê²Œ 1~3ê°œ ê¸°ë²• ì„ íƒí•˜ì—¬ ì—°ì† ì ìš©
        num_techniques = random.randint(1, 3)
        selected_techniques = random.sample(techniques, num_techniques)

        variant = original_q
        for technique in selected_techniques:
            variants = technique(variant)
            if variants:
                variant = random.choice(variants)

        # ì˜¤íƒ€ ìˆ˜ì •
        variant = self._fix_typos(variant)

        return variant

    def _ë³€í˜•_ì–´ë¯¸(self, question: str) -> List[str]:
        """ì–´ë¯¸ ë³€í˜•"""
        variants = []

        patterns = [
            (r'(.+)í•˜ë‚˜ìš”\?', [r'\1í•´ìš”?', r'\1í• ê¹Œìš”?', r'\1í•˜ì£ ?', r'\1í•©ë‹ˆê¹Œ?', r'\1í•˜ì„¸ìš”?']),
            (r'(.+)ì¸ê°€ìš”\?', [r'\1ì´ì—ìš”?', r'\1ì¼ê¹Œìš”?', r'\1ì´ì£ ?', r'\1ì…ë‹ˆê¹Œ?', r'\1ì˜ˆìš”?']),
            (r'(.+)ìˆë‚˜ìš”\?', [r'\1ìˆì–´ìš”?', r'\1ìˆì„ê¹Œìš”?', r'\1ìˆì£ ?', r'\1ìˆìŠµë‹ˆê¹Œ?']),
            (r'(.+)ë˜ë‚˜ìš”\?', [r'\1ë¼ìš”?', r'\1ë ê¹Œìš”?', r'\1ë˜ì£ ?', r'\1ë©ë‹ˆê¹Œ?', r'\1ë˜ë‚˜ìš”']),
            (r'(.+)ê°€ëŠ¥í•œê°€ìš”\?', [r'\1ê°€ëŠ¥í•´ìš”?', r'\1ê°€ëŠ¥í• ê¹Œìš”?', r'\1í•  ìˆ˜ ìˆë‚˜ìš”?', r'\1ê°€ëŠ¥í•œì§€ìš”?']),
        ]

        for pattern, replacements in patterns:
            if re.search(pattern, question):
                for repl in replacements:
                    variant = re.sub(pattern, repl, question)
                    if variant != question:
                        variants.append(variant)

        return variants

    def _ë³€í˜•_ì§ˆë¬¸í˜•ì‹(self, question: str) -> List[str]:
        """ì§ˆë¬¸ í˜•ì‹ ë³€í˜•"""
        variants = []

        patterns = [
            (r'(.+) ì–´ë–»ê²Œ (.+)\?', [r'\1 \2 ë°©ë²•ì€?', r'\2 ë°©ë²• ì•Œë ¤ì£¼ì„¸ìš”', r'\1 ì–´ë–¤ ë°©ë²•ìœ¼ë¡œ \2?']),
            (r'(.+) ë­”ê°€ìš”\?', [r'\1ì´ ë¬´ì—‡ì¸ê°€ìš”?', r'\1ì— ëŒ€í•´ ì•Œë ¤ì£¼ì„¸ìš”', r'\1 ì„¤ëª…í•´ì£¼ì„¸ìš”']),
            (r'(.+) ì–´ë””ì„œ (.+)\?', [r'\2 ì–´ë””ì—ì„œ í•˜ë‚˜ìš”?', r'\1 \2 ìœ„ì¹˜ëŠ”?', r'\2 ê³³ì€ ì–´ë””ì¸ê°€ìš”?']),
            (r'(.+) ê°€ëŠ¥í•œê°€ìš”\?', [r'\1 ìˆ˜ ìˆë‚˜ìš”?', r'\1 ê°€ëŠ¥ì—¬ë¶€ëŠ”?', r'\1 ë˜ë‚˜ìš”?']),
        ]

        for pattern, replacements in patterns:
            if re.search(pattern, question):
                for repl in replacements:
                    try:
                        variant = re.sub(pattern, repl, question)
                        if variant != question:
                            variants.append(variant)
                    except:
                        pass

        return variants

    def _ë³€í˜•_ë™ì˜ì–´(self, question: str) -> List[str]:
        """ë™ì˜ì–´ ì¹˜í™˜"""
        variants = []

        for word, synonyms in self.synonyms.items():
            if word in question:
                for synonym in synonyms:
                    variant = question.replace(word, synonym, 1)  # ì²« ë²ˆì§¸ë§Œ ì¹˜í™˜
                    if variant != question:
                        variants.append(variant)

        return variants

    def _ë³€í˜•_ì¡°ì‚¬(self, question: str) -> List[str]:
        """ì¡°ì‚¬ ë³€í˜•"""
        variants = []

        replacements = [
            ('ì€', 'ëŠ”'),
            ('ëŠ”', 'ì€'),
            ('ì´', 'ê°€'),
            ('ê°€', 'ì´'),
            ('ì„', 'ë¥¼'),
            ('ë¥¼', 'ì„'),
            ('ê³¼', 'ì™€'),
            ('ì™€', 'ê³¼'),
        ]

        for old, new in replacements:
            if old in question:
                variant = question.replace(old, new, 1)
                if variant != question:
                    variants.append(variant)

        return variants

    def _ë³€í˜•_ì¶•ì•½í™•ì¥(self, question: str) -> List[str]:
        """ì¶•ì•½/í™•ì¥"""
        variants = []

        # ì¶•ì•½ íŒ¨í„´
        abbr_patterns = [
            (r'(.+) ì–´ë–»ê²Œ (.+)\?', r'\1 \2?'),
            (r'(.+)ì— ëŒ€í•´ (.+)\?', r'\1 \2?'),
            (r'(.+)í•˜ëŠ” ë°©ë²•', r'\1 ë°©ë²•'),
        ]

        for pattern, replacement in abbr_patterns:
            if re.search(pattern, question):
                variant = re.sub(pattern, replacement, question)
                if variant != question:
                    variants.append(variant)

        # í™•ì¥ íŒ¨í„´
        if not question.endswith('?'):
            variants.append(question + '?')

        return variants

    def _ë³€í˜•_ë‹¨ì–´ìˆœì„œ(self, question: str) -> List[str]:
        """ë‹¨ì–´ ìˆœì„œ ë³€ê²½ (ì œí•œì )"""
        variants = []

        patterns = [
            (r'(.+)ì™€ (.+) ì°¨ì´', r'\2ì™€ \1 ì°¨ì´'),
            (r'(.+) ì–´ë””ì„œ (.+)', r'\2 ì–´ë””ì„œ í•˜ë‚˜ìš”?'),
        ]

        for pattern, replacement in patterns:
            if re.search(pattern, question):
                variant = re.sub(pattern, replacement, question)
                if variant != question:
                    variants.append(variant)

        return variants

    def _ë³€í˜•_ì˜ë¬¸ì‚¬(self, question: str) -> List[str]:
        """ì˜ë¬¸ì‚¬ ë³€í˜•"""
        variants = []

        replacements = [
            ('ë­”ê°€ìš”', 'ë¬´ì—‡ì¸ê°€ìš”'),
            ('ë¬´ì—‡ì¸ê°€ìš”', 'ë­”ê°€ìš”'),
            ('ì–´ë–»ê²Œ', 'ì–´ë–¤ ë°©ë²•ìœ¼ë¡œ'),
            ('ì–´ë–¤ ë°©ë²•ìœ¼ë¡œ', 'ì–´ë–»ê²Œ'),
            ('ì–´ë””ì„œ', 'ì–´ëŠ ê³³ì—ì„œ'),
            ('ì–´ëŠ ê³³ì—ì„œ', 'ì–´ë””ì„œ'),
            ('ì–¸ì œ', 'ëª‡ ì‹œì—'),
            ('ì™œ', 'ì–´ë–¤ ì´ìœ ë¡œ'),
            ('ì–¼ë§ˆë‚˜', 'ì–´ëŠ ì •ë„'),
        ]

        for old, new in replacements:
            if old in question:
                variant = question.replace(old, new)
                if variant != question:
                    variants.append(variant)

        return variants

    def _ë³€í˜•_ì ‘ë‘ì ‘ë¯¸ì‚¬(self, question: str) -> List[str]:
        """ì ‘ë‘ì‚¬/ì ‘ë¯¸ì‚¬ ì¶”ê°€"""
        variants = []

        # ì ‘ë‘ì‚¬ ì¶”ê°€
        for prefix in self.question_prefixes:
            if not question.startswith(prefix):
                variant = prefix + question
                variants.append(variant)

        # ì ‘ë¯¸ì‚¬ ì¶”ê°€ (ë¬¼ìŒí‘œ ì œê±° í›„)
        q_without_mark = question.rstrip('?')
        for suffix in self.question_suffixes:
            if suffix and not question.endswith(suffix):
                variant = q_without_mark + suffix
                if not variant.endswith('?'):
                    variant += '?'
                variants.append(variant)

        return variants

    def _ë³€í˜•_ì¡´ëŒ“ë§ë°˜ë§(self, question: str) -> List[str]:
        """ì¡´ëŒ“ë§/ë°˜ë§ ë³€í™˜"""
        variants = []

        # ì¡´ëŒ“ë§ -> ë°˜ë§
        formal_to_casual = [
            ('í•˜ë‚˜ìš”', 'í•´'),
            ('ì¸ê°€ìš”', 'ì´ì•¼'),
            ('ìˆë‚˜ìš”', 'ìˆì–´'),
            ('ë˜ë‚˜ìš”', 'ë¼'),
            ('ì•Œë ¤ì£¼ì„¸ìš”', 'ì•Œë ¤ì¤˜'),
            ('ì„¤ëª…í•´ì£¼ì„¸ìš”', 'ì„¤ëª…í•´ì¤˜'),
        ]

        # ë°˜ë§ -> ì¡´ëŒ“ë§
        casual_to_formal = [
            ('í•´', 'í•©ë‹ˆê¹Œ'),
            ('ì´ì•¼', 'ì…ë‹ˆê¹Œ'),
            ('ìˆì–´', 'ìˆìŠµë‹ˆê¹Œ'),
            ('ë¼', 'ë©ë‹ˆê¹Œ'),
            ('ì•Œë ¤ì¤˜', 'ì•Œë ¤ì£¼ì‹­ì‹œì˜¤'),
        ]

        for old, new in formal_to_casual + casual_to_formal:
            if old in question:
                variant = question.replace(old, new)
                if variant != question:
                    variants.append(variant)

        return variants

    def _ë³€í˜•_ë¶€ê°€í‘œí˜„(self, question: str) -> List[str]:
        """ë¶€ê°€ í‘œí˜„ ì¶”ê°€"""
        variants = []

        additional_phrases = [
            ('ì¡°íšŒ', 'ì¡°íšŒ ë° ê²€ìƒ‰'),
            ('ë°ì´í„°', 'ë°ì´í„°ì…‹'),
            ('ì‹ ì²­', 'ì‹ ì²­ ë° ë“±ë¡'),
            ('ë°©ë²•', 'ìƒì„¸ ë°©ë²•'),
            ('ì •ë³´', 'ìƒì„¸ ì •ë³´'),
            ('í†µê³„', 'í†µê³„ ì •ë³´'),
        ]

        for word, expanded in additional_phrases:
            if word in question and expanded not in question:
                variant = question.replace(word, expanded, 1)
                if variant != question:
                    variants.append(variant)

        return variants

    def _fix_typos(self, text: str) -> str:
        """ì˜¤íƒ€/ë§ì¶¤ë²• ìˆ˜ì •"""

        # ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤íƒ€ íŒ¨í„´
        typo_fixes = [
            ('ë°ê°€í„°', 'ë°ì´í„°'),
            ('ë°ì´ê°€', 'ë°ì´í„°'),
            ('  ', ' '),  # ì¤‘ë³µ ê³µë°±
            (' ?', '?'),  # ê³µë°± + ë¬¼ìŒí‘œ
            ('??', '?'),  # ì¤‘ë³µ ë¬¼ìŒí‘œ
        ]

        for wrong, correct in typo_fixes:
            text = text.replace(wrong, correct)

        # ì¡°ì‚¬ ì¤‘ë³µ ì œê±°
        text = re.sub(r'([ê°€-í£])ëŠ”ëŠ”', r'\1ëŠ”', text)
        text = re.sub(r'([ê°€-í£])ì€ì€', r'\1ì€', text)
        text = re.sub(r'([ê°€-í£])ì„ì„', r'\1ì„', text)
        text = re.sub(r'([ê°€-í£])ë¥¼ë¥¼', r'\1ë¥¼', text)

        return text.strip()

    def get_statistics(self) -> Dict:
        """í†µê³„ ì •ë³´"""
        questions = [item['instruction'] for item in self.training_data]
        answers = [item['output'] for item in self.training_data]

        q_lengths = [len(q) for q in questions]
        a_lengths = [len(a) for a in answers]

        # ë©”ë‰´ë³„ ë¶„í¬
        menu_dist = Counter()
        topic_dist = Counter()
        for item in self.training_data:
            menu_name = item['metadata']['menu_name']
            topic_name = item['metadata']['topic_name']
            menu_dist[menu_name] += 1
            topic_dist[topic_name] += 1

        return {
            "total": len(self.training_data),
            "q_length_avg": sum(q_lengths) / len(q_lengths) if q_lengths else 0,
            "q_length_min": min(q_lengths) if q_lengths else 0,
            "q_length_max": max(q_lengths) if q_lengths else 0,
            "a_length_avg": sum(a_lengths) / len(a_lengths) if a_lengths else 0,
            "a_length_min": min(a_lengths) if a_lengths else 0,
            "a_length_max": max(a_lengths) if a_lengths else 0,
            "menu_distribution": menu_dist.most_common(),
            "topic_distribution": topic_dist.most_common(),
        }

    def save_jsonl(self, output_path: str, include_metadata: bool = False):
        """JSONL ì €ì¥ (í•™ìŠµìš©)"""
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            for item in self.training_data:
                if include_metadata:
                    f.write(json.dumps(item, ensure_ascii=False) + '\n')
                else:
                    # ë©”íƒ€ë°ì´í„° ì œì™¸
                    simple_item = {
                        "instruction": item['instruction'],
                        "input": item['input'],
                        "output": item['output']
                    }
                    f.write(json.dumps(simple_item, ensure_ascii=False) + '\n')

        print(f"âœ… JSONL ì €ì¥ ì™„ë£Œ: {output_path}")
        print(f"   ì´ {len(self.training_data):,}ê±´\n")

    def save_json(self, output_path: str, include_metadata: bool = True):
        """JSON ì €ì¥ (ê²€í† ìš©)"""
        output_path = Path(output_path)
        output_path.parent.mkdir(parents=True, exist_ok=True)

        if include_metadata:
            data = self.training_data
        else:
            data = [
                {
                    "instruction": item['instruction'],
                    "input": item['input'],
                    "output": item['output']
                }
                for item in self.training_data
            ]

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        print(f"âœ… JSON ì €ì¥ ì™„ë£Œ: {output_path}\n")

    def print_samples(self, count: int = 10):
        """ìƒ˜í”Œ ì¶œë ¥"""
        print(f"{'='*80}")
        print(f"ğŸ“ ë¬´ì‘ìœ„ ìƒ˜í”Œ {count}ê°œ")
        print(f"{'='*80}\n")

        samples = random.sample(self.training_data, min(count, len(self.training_data)))

        for i, sample in enumerate(samples, 1):
            print(f"[ìƒ˜í”Œ {i}]")
            print(f"ë©”ë‰´: {sample['metadata']['menu_name']} > {sample['metadata']['topic_name']}")
            print(f"Q: {sample['instruction']}")
            print(f"A: {sample['output'][:100]}...\n")

    def print_statistics(self):
        """í†µê³„ ì¶œë ¥"""
        stats = self.get_statistics()

        print(f"{'='*80}")
        print(f"ğŸ“Š ë°ì´í„° í†µê³„")
        print(f"{'='*80}\n")

        print(f"[ì „ì²´]")
        print(f"  ì´ ë°ì´í„°: {stats['total']:,}ê±´\n")

        print(f"[ì§ˆë¬¸ ê¸¸ì´]")
        print(f"  í‰ê· : {stats['q_length_avg']:.1f}ì")
        print(f"  ìµœì†Œ: {stats['q_length_min']}ì")
        print(f"  ìµœëŒ€: {stats['q_length_max']}ì\n")

        print(f"[ë‹µë³€ ê¸¸ì´]")
        print(f"  í‰ê· : {stats['a_length_avg']:.1f}ì")
        print(f"  ìµœì†Œ: {stats['a_length_min']}ì")
        print(f"  ìµœëŒ€: {stats['a_length_max']}ì\n")

        print(f"[ë©”ë‰´ë³„ ë¶„í¬]")
        for menu_name, count in stats['menu_distribution']:
            pct = (count / stats['total']) * 100
            print(f"  {menu_name:30s}: {count:6,}ê±´ ({pct:5.1f}%)")

        print(f"\n[ì£¼ì œë³„ ë¶„í¬ TOP 10]")
        for i, (topic_name, count) in enumerate(stats['topic_distribution'][:10], 1):
            pct = (count / stats['total']) * 100
            print(f"  {i:2d}. {topic_name:30s}: {count:6,}ê±´ ({pct:5.1f}%)")


def main():
    # ê²½ë¡œ ì„¤ì •
    structure_path = "/home/user/bigdataptAI/bigdata_portal_learning/config/hira_opendata_structure.yaml"
    output_dir = "/home/user/bigdataptAI/bigdata_portal_learning/output"

    output_jsonl_train = f"{output_dir}/hira_opendata_train.jsonl"
    output_jsonl_full = f"{output_dir}/hira_opendata_train_with_metadata.jsonl"
    output_json = f"{output_dir}/hira_opendata_train.json"

    # ìƒì„±ê¸° ì´ˆê¸°í™”
    print("HIRA ì˜¤í”ˆë°ì´í„° í¬í„¸ í•™ìŠµ ë°ì´í„° ìƒì„±ê¸°")
    print("="*80)
    generator = HIRAOpenDataGenerator(structure_path)

    # ë°ì´í„° ìƒì„± (ì£¼ì œë³„ 3,000ê±´ ëª©í‘œ)
    generator.generate(target_per_topic=3000)

    # í†µê³„ ì¶œë ¥
    generator.print_statistics()

    # ìƒ˜í”Œ ì¶œë ¥
    generator.print_samples(15)

    # ì €ì¥
    generator.save_jsonl(output_jsonl_train, include_metadata=False)  # í•™ìŠµìš© (ë©”íƒ€ë°ì´í„° ì œì™¸)
    generator.save_jsonl(output_jsonl_full, include_metadata=True)    # ì „ì²´ (ë©”íƒ€ë°ì´í„° í¬í•¨)
    generator.save_json(output_json, include_metadata=True)           # JSON (ê²€í† ìš©)

    print(f"{'='*80}")
    print(f"âœ… HIRA ì˜¤í”ˆë°ì´í„° í•™ìŠµ ë°ì´í„° ìƒì„± ì™„ë£Œ!")
    print(f"{'='*80}\n")

    print(f"ğŸ“ ìƒì„± íŒŒì¼:")
    print(f"  1. {output_jsonl_train} (í•™ìŠµìš©, ë©”íƒ€ë°ì´í„° ì œì™¸)")
    print(f"  2. {output_jsonl_full} (ì „ì²´, ë©”íƒ€ë°ì´í„° í¬í•¨)")
    print(f"  3. {output_json} (JSON, ê²€í† ìš©)\n")


if __name__ == "__main__":
    main()
