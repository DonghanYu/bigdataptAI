#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
ì¤‘ë³µ ì œê±°, ìœ íš¨ì„± ì²´í¬, í†µê³„ ë¶„ì„
"""

import json
from pathlib import Path
from collections import Counter
from typing import List, Dict, Tuple

class DataQualityValidator:
    def __init__(self, data_path: str):
        """
        í’ˆì§ˆ ê²€ì¦ê¸° ì´ˆê¸°í™”

        Args:
            data_path: ê²€ì¦í•  JSONL íŒŒì¼ ê²½ë¡œ
        """
        self.data_path = Path(data_path)
        self.data = []
        self.load_data()

    def load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        print(f"ë°ì´í„° ë¡œë“œ ì¤‘: {self.data_path}")

        with open(self.data_path, 'r', encoding='utf-8') as f:
            for line in f:
                try:
                    item = json.loads(line.strip())
                    self.data.append(item)
                except:
                    continue

        print(f"âœ… ë¡œë“œ ì™„ë£Œ: {len(self.data):,}ê±´\n")

    def check_duplicates(self) -> Tuple[int, List[str]]:
        """ì¤‘ë³µ ì²´í¬"""
        print("="*80)
        print("1ï¸âƒ£  ì¤‘ë³µ ì²´í¬")
        print("="*80)

        questions = [item['instruction'] for item in self.data]
        question_counts = Counter(questions)

        duplicates = {q: count for q, count in question_counts.items() if count > 1}

        if duplicates:
            print(f"âš ï¸  ì¤‘ë³µ ë°œê²¬: {len(duplicates)}ê°œ ì§ˆë¬¸ì´ ì¤‘ë³µë¨")
            print("\n[ì¤‘ë³µ ì§ˆë¬¸ TOP 10]")
            for i, (q, count) in enumerate(sorted(duplicates.items(), key=lambda x: x[1], reverse=True)[:10], 1):
                print(f"  {i}. ({count}ë²ˆ) {q}")
        else:
            print("âœ… ì¤‘ë³µ ì—†ìŒ: ëª¨ë“  ì§ˆë¬¸ì´ ê³ ìœ í•©ë‹ˆë‹¤")

        return len(duplicates), list(duplicates.keys())

    def check_length(self):
        """ê¸¸ì´ ì²´í¬"""
        print("\n" + "="*80)
        print("2ï¸âƒ£  ê¸¸ì´ ì²´í¬")
        print("="*80)

        q_lengths = [len(item['instruction']) for item in self.data]
        a_lengths = [len(item['output']) for item in self.data]

        print(f"\n[ì§ˆë¬¸ ê¸¸ì´]")
        print(f"  í‰ê· : {sum(q_lengths) / len(q_lengths):.1f}ì")
        print(f"  ìµœì†Œ: {min(q_lengths)}ì")
        print(f"  ìµœëŒ€: {max(q_lengths)}ì")
        print(f"  ì¤‘ì•™ê°’: {sorted(q_lengths)[len(q_lengths)//2]}ì")

        # ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ ì§ˆë¬¸
        too_short = [item for item in self.data if len(item['instruction']) < 5]
        too_long = [item for item in self.data if len(item['instruction']) > 100]

        if too_short:
            print(f"\n  âš ï¸  ë„ˆë¬´ ì§§ì€ ì§ˆë¬¸ ({len(too_short)}ê±´): 5ì ë¯¸ë§Œ")
            for item in too_short[:3]:
                print(f"     - {item['instruction']}")

        if too_long:
            print(f"\n  âš ï¸  ë„ˆë¬´ ê¸´ ì§ˆë¬¸ ({len(too_long)}ê±´): 100ì ì´ˆê³¼")
            for item in too_long[:3]:
                print(f"     - {item['instruction'][:80]}...")

        print(f"\n[ë‹µë³€ ê¸¸ì´]")
        print(f"  í‰ê· : {sum(a_lengths) / len(a_lengths):.1f}ì")
        print(f"  ìµœì†Œ: {min(a_lengths)}ì")
        print(f"  ìµœëŒ€: {max(a_lengths)}ì")
        print(f"  ì¤‘ì•™ê°’: {sorted(a_lengths)[len(a_lengths)//2]}ì")

        # ë„ˆë¬´ ì§§ê±°ë‚˜ ê¸´ ë‹µë³€
        too_short_a = [item for item in self.data if len(item['output']) < 30]
        too_long_a = [item for item in self.data if len(item['output']) > 500]

        if too_short_a:
            print(f"\n  âš ï¸  ë„ˆë¬´ ì§§ì€ ë‹µë³€ ({len(too_short_a)}ê±´): 30ì ë¯¸ë§Œ")
            for item in too_short_a[:3]:
                print(f"     Q: {item['instruction']}")
                print(f"     A: {item['output']}\n")

        if too_long_a:
            print(f"\n  âš ï¸  ë„ˆë¬´ ê¸´ ë‹µë³€ ({len(too_long_a)}ê±´): 500ì ì´ˆê³¼")

    def check_quality(self):
        """í’ˆì§ˆ ì²´í¬"""
        print("\n" + "="*80)
        print("3ï¸âƒ£  í’ˆì§ˆ ì²´í¬")
        print("="*80)

        issues = []

        # 1. ë¹ˆ ë‹µë³€ ì²´í¬
        empty_output = [item for item in self.data if not item.get('output', '').strip()]
        if empty_output:
            issues.append(f"ë¹ˆ ë‹µë³€: {len(empty_output)}ê±´")

        # 2. ë¹ˆ ì§ˆë¬¸ ì²´í¬
        empty_instruction = [item for item in self.data if not item.get('instruction', '').strip()]
        if empty_instruction:
            issues.append(f"ë¹ˆ ì§ˆë¬¸: {len(empty_instruction)}ê±´")

        # 3. ì§ˆë¬¸ê³¼ ë‹µë³€ì´ ë™ì¼í•œ ê²½ìš°
        same_qa = [item for item in self.data if item.get('instruction', '') == item.get('output', '')]
        if same_qa:
            issues.append(f"ì§ˆë¬¸=ë‹µë³€: {len(same_qa)}ê±´")

        # 4. í…œí”Œë¦¿ ë¬¸êµ¬ê°€ ê·¸ëŒ€ë¡œ ë‚¨ì•„ìˆëŠ” ê²½ìš°
        template_remaining = []
        for item in self.data:
            if '{' in item['instruction'] or '}' in item['instruction']:
                template_remaining.append(item)
            if '{' in item['output'] or '}' in item['output']:
                template_remaining.append(item)

        if template_remaining:
            issues.append(f"í…œí”Œë¦¿ ë¯¸ì¹˜í™˜: {len(template_remaining)}ê±´")
            print(f"\n  âš ï¸  í…œí”Œë¦¿ ë¬¸êµ¬ ë¯¸ì¹˜í™˜ ìƒ˜í”Œ:")
            for item in template_remaining[:3]:
                print(f"     Q: {item['instruction']}")
                print(f"     A: {item['output'][:80]}...\n")

        # 5. ê¸°ë³¸ ë‹µë³€ ë¹„ìœ¨ ì²´í¬ (fallback ë‹µë³€)
        fallback_pattern = "ë¹…ë°ì´í„°ê°œë°©í¬í„¸ì˜ í•´ë‹¹ ë©”ë‰´ì—ì„œ ì´ìš©í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤"
        fallback_count = sum(1 for item in self.data if fallback_pattern in item['output'])
        fallback_ratio = (fallback_count / len(self.data)) * 100

        print(f"\n[í’ˆì§ˆ ì§€í‘œ]")
        print(f"  ë¹ˆ ë‹µë³€: {len(empty_output)}ê±´")
        print(f"  ë¹ˆ ì§ˆë¬¸: {len(empty_instruction)}ê±´")
        print(f"  ì§ˆë¬¸=ë‹µë³€: {len(same_qa)}ê±´")
        print(f"  í…œí”Œë¦¿ ë¯¸ì¹˜í™˜: {len(template_remaining)}ê±´")
        print(f"  ê¸°ë³¸ ë‹µë³€ ë¹„ìœ¨: {fallback_ratio:.1f}% ({fallback_count:,}/{len(self.data):,}ê±´)")

        if fallback_ratio > 30:
            print(f"    âš ï¸  ê¸°ë³¸ ë‹µë³€ì´ ë„ˆë¬´ ë§ìŠµë‹ˆë‹¤ (30% ì´ˆê³¼)")

        if not issues:
            print("\nâœ… í’ˆì§ˆ ë¬¸ì œ ì—†ìŒ")
        else:
            print(f"\nâš ï¸  ë°œê²¬ëœ ë¬¸ì œ: {len(issues)}ê°œ")
            for issue in issues:
                print(f"  - {issue}")

        return issues

    def check_variety(self):
        """ë‹¤ì–‘ì„± ì²´í¬"""
        print("\n" + "="*80)
        print("4ï¸âƒ£  ë‹¤ì–‘ì„± ì²´í¬")
        print("="*80)

        # ì§ˆë¬¸ ì‹œì‘ íŒ¨í„´ ë¶„ì„
        start_patterns = Counter()
        for item in self.data:
            q = item['instruction']
            # ì²« 2ë‹¨ì–´ ì¶”ì¶œ
            words = q.split()[:2]
            pattern = ' '.join(words) if len(words) >= 2 else q
            start_patterns[pattern] += 1

        print(f"\n[ì§ˆë¬¸ ì‹œì‘ íŒ¨í„´ TOP 15]")
        for i, (pattern, count) in enumerate(start_patterns.most_common(15), 1):
            percentage = (count / len(self.data)) * 100
            print(f"  {i:2d}. {pattern:30s}: {count:4,}ê±´ ({percentage:4.1f}%)")

        # ë‹µë³€ ì‹œì‘ íŒ¨í„´ ë¶„ì„
        answer_start_patterns = Counter()
        for item in self.data:
            a = item['output']
            # ì²« 5ë‹¨ì–´ ì¶”ì¶œ
            words = a.split()[:5]
            pattern = ' '.join(words) if len(words) >= 5 else a[:20]
            answer_start_patterns[pattern] += 1

        print(f"\n[ë‹µë³€ ì‹œì‘ íŒ¨í„´ TOP 10]")
        for i, (pattern, count) in enumerate(answer_start_patterns.most_common(10), 1):
            percentage = (count / len(self.data)) * 100
            print(f"  {i:2d}. {pattern:50s}: {count:4,}ê±´ ({percentage:4.1f}%)")

    def remove_duplicates(self, output_path: str):
        """ì¤‘ë³µ ì œê±° í›„ ì €ì¥"""
        print("\n" + "="*80)
        print("5ï¸âƒ£  ì¤‘ë³µ ì œê±°")
        print("="*80)

        seen_questions = set()
        unique_data = []

        for item in self.data:
            q = item['instruction']
            if q not in seen_questions:
                seen_questions.add(q)
                unique_data.append(item)

        removed = len(self.data) - len(unique_data)

        print(f"  ì›ë³¸: {len(self.data):,}ê±´")
        print(f"  ê³ ìœ : {len(unique_data):,}ê±´")
        print(f"  ì œê±°: {removed:,}ê±´")

        if removed > 0:
            # ì €ì¥
            output_path = Path(output_path)
            output_path.parent.mkdir(parents=True, exist_ok=True)

            with open(output_path, 'w', encoding='utf-8') as f:
                for item in unique_data:
                    f.write(json.dumps(item, ensure_ascii=False) + '\n')

            print(f"\n  âœ… ì €ì¥ ì™„ë£Œ: {output_path}")
        else:
            print(f"\n  âœ… ì¤‘ë³µ ì—†ìŒ: ì €ì¥ ìŠ¤í‚µ")

        return len(unique_data)

    def generate_report(self):
        """ì „ì²´ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\n" + "="*80)
        print("ğŸ“Š ì¢…í•© í’ˆì§ˆ ë¦¬í¬íŠ¸")
        print("="*80)

        # 1. ì¤‘ë³µ ì²´í¬
        dup_count, _ = self.check_duplicates()

        # 2. ê¸¸ì´ ì²´í¬
        self.check_length()

        # 3. í’ˆì§ˆ ì²´í¬
        issues = self.check_quality()

        # 4. ë‹¤ì–‘ì„± ì²´í¬
        self.check_variety()

        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        print("\n" + "="*80)
        print("âœ¨ ì¢…í•© í‰ê°€")
        print("="*80)

        score = 100
        if dup_count > 0:
            score -= min(20, dup_count)
        if issues:
            score -= len(issues) * 5

        print(f"\n  í’ˆì§ˆ ì ìˆ˜: {score}/100")

        if score >= 90:
            print(f"  ë“±ê¸‰: â­â­â­â­â­ ë§¤ìš° ìš°ìˆ˜")
        elif score >= 80:
            print(f"  ë“±ê¸‰: â­â­â­â­ ìš°ìˆ˜")
        elif score >= 70:
            print(f"  ë“±ê¸‰: â­â­â­ ì–‘í˜¸")
        elif score >= 60:
            print(f"  ë“±ê¸‰: â­â­ ë³´í†µ")
        else:
            print(f"  ë“±ê¸‰: â­ ê°œì„  í•„ìš”")

        print("\n  ê¶Œì¥ ì‚¬í•­:")
        if dup_count > 0:
            print(f"    - ì¤‘ë³µ {dup_count}ê±´ ì œê±° ê¶Œì¥")
        if not issues:
            print(f"    - ë°ì´í„° í’ˆì§ˆ ìš°ìˆ˜, LoRA í•™ìŠµ ì§„í–‰ ê°€ëŠ¥")
        else:
            print(f"    - {len(issues)}ê°œ í’ˆì§ˆ ì´ìŠˆ ê°œì„  ê¶Œì¥")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""

    # ê²½ë¡œ ì„¤ì •
    input_file = Path(__file__).parent.parent / 'output' / 'bigdata_portal_train.jsonl'
    output_file = Path(__file__).parent.parent / 'output' / 'bigdata_portal_train_clean.jsonl'

    # ê²€ì¦ê¸° ì‹¤í–‰
    validator = DataQualityValidator(input_file)

    # ì „ì²´ ë¦¬í¬íŠ¸ ìƒì„±
    validator.generate_report()

    # ì¤‘ë³µ ì œê±° í›„ ì €ì¥
    final_count = validator.remove_duplicates(output_file)

    print("\n" + "="*80)
    print("âœ… í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ!")
    print("="*80)
    print(f"\n  ì›ë³¸ íŒŒì¼: {input_file}")
    print(f"  ì •ì œ íŒŒì¼: {output_file}")
    print(f"  ìµœì¢… ë°ì´í„°: {final_count:,}ê±´")


if __name__ == "__main__":
    main()
