# HIRA λΉ…λ°μ΄ν„° μƒλ‹΄ μ±—λ΄‡ λ¨λΈ κµ¬μ¶• ν”„λ΅μ νΈ

**ν”„λ΅μ νΈλ…**: HIRA λΉ…λ°μ΄ν„° μƒλ‹΄ μ±—λ΄‡
**λ²„μ „**: 1.0.0
**λ‚ μ§**: 2025-11-13
**λ¨λΈ**: SOLAR-10.7B-v1.0 + LoRA

---

## π“‹ ν”„λ΅μ νΈ κ°μ”

κ±΄κ°•λ³΄ν—μ‹¬μ‚¬ν‰κ°€μ›(HIRA) λΉ…λ°μ΄ν„°κ°λ°©μ‹μ¤ν…μ λ°μ΄ν„°λ¥Ό κΈ°λ°μΌλ΅ κ±΄κ°•λ³΄ν— κ΄€λ ¨ μ§μμ‘λ‹µμ„ μν–‰ν•λ” μ±—λ΄‡ λ¨λΈμ„ κµ¬μ¶•ν•λ” ν”„λ΅μ νΈμ…λ‹λ‹¤.

### μ£Όμ” λ©ν‘

1. **ν•™μµ λ°μ΄ν„°**: μ‹¬ν‰μ› λΉ…λ°μ΄ν„°κ°λ°©μ‹μ¤ν… κΈ°λ° λ°μ΄ν„° λ§λ ¨
2. **λ¨λΈ ν•™μµ**: νμ‡„λ§ ν™κ²½μ—μ„ SOLAR-10.7B LoRA λ―Έμ„Έμ΅°μ •
3. **λ¨λΈ μ‹¤μ¦**: μΈν„°νμ΄μ¤λ¥Ό ν†µν• μ‚¬λ ν‰κ°€

### κΈ°μ  μ¤νƒ

- **λ¨λΈ**: SOLAR-10.7B-v1.0
- **λ―Έμ„Έμ΅°μ •**: LoRA (Low-Rank Adaptation)
- **ν”„λ μ„μ›ν¬**: PyTorch 2.1, Transformers, PEFT
- **ν™κ²½**: A100 80G x2, CPU 32 Core, Mem 800G
- **μΈν„°νμ΄μ¤**: JupyterLab, Flask, Gradio (μ„ νƒ)

---

## π—‚οΈ ν”„λ΅μ νΈ κµ¬μ΅°

```
bigdataptAI/
β”β”€β”€ README.md                          # κΈ°λ³Έ README
β”β”€β”€ PROJECT_README.md                  # ν”„λ΅μ νΈ μƒμ„Έ λ¬Έμ„ (λ³Έ λ¬Έμ„)
β”β”€β”€ config/
β”‚   β””β”€β”€ config.yaml                    # μ„¤μ • νμΌ
β”β”€β”€ docs/
β”‚   β””β”€β”€ 01_HIRA_DATA_PREPARATION_GUIDE.md  # λ°μ΄ν„° μ¤€λΉ„ κ°€μ΄λ“
β”β”€β”€ notebooks/
β”‚   β”β”€β”€ HIRA_Training_SOLAR_LoRA.ipynb     # ν•™μµ λ…ΈνΈλ¶
β”‚   β””β”€β”€ HIRA_Interface.ipynb               # μΈν„°νμ΄μ¤ λ…ΈνΈλ¶
β”β”€β”€ workspace/
β”‚   β”β”€β”€ data/
β”‚   β”‚   β””β”€β”€ hira/
β”‚   β”‚       β”β”€β”€ raw/                   # μ›λ³Έ λ°μ΄ν„°
β”‚   β”‚       β”β”€β”€ processed/             # κ°€κ³µ λ°μ΄ν„°
β”‚   β”‚       β””β”€β”€ cleaned/               # μ •μ  λ°μ΄ν„°
β”‚   β”‚           β”β”€β”€ train.jsonl
β”‚   β”‚           β”β”€β”€ val.jsonl
β”‚   β”‚           β””β”€β”€ test.jsonl
β”‚   β”β”€β”€ models/
β”‚   β”‚   β””β”€β”€ solar_hira_lora/
β”‚   β”‚       β”β”€β”€ best_model/            # Best μ²΄ν¬ν¬μΈνΈ
β”‚   β”‚       β”β”€β”€ final_model/           # μµμΆ… λ¨λΈ
β”‚   β”‚       β””β”€β”€ training_history.json  # ν•™μµ νμ¤ν† λ¦¬
β”‚   β””β”€β”€ logs/                          # λ΅κ·Έ νμΌ
β”β”€β”€ solar_10.7b_package/
β”‚   β””β”€β”€ model/                         # SOLAR-10.7B λ¨λΈ
β”β”€β”€ scripts/ (κΈ°μ΅΄ Python μ¤ν¬λ¦½νΈ)
β”‚   β”β”€β”€ 01_data_cleaning.py
β”‚   β”β”€β”€ 02_train_with_validation.py
β”‚   β”β”€β”€ 03_improved_interface.py
β”‚   β”β”€β”€ 04_evaluate_model.py
β”‚   β””β”€β”€ 05_data_augmentation.py
β””β”€β”€ train_solar                        # κΈ°λ³Έ ν•™μµ μ¤ν¬λ¦½νΈ
```

---

## π€ λΉ λ¥Έ μ‹μ‘

### μ „μ  μ΅°κ±΄

```bash
# ν•„μ λΌμ΄λΈλ¬λ¦¬ (νμ‡„λ§μ—μ„ λ―Έλ¦¬ μ„¤μΉ ν•„μ”)
torch==2.1.0
transformers>=4.36.0
peft>=0.7.0
accelerate>=0.25.0
datasets>=2.15.0
tqdm
matplotlib
ipywidgets  # JupyterLab μΈν„°νμ΄μ¤μ©
```

### 1λ‹¨κ³„: ν™κ²½ μ„¤μ •

```bash
# 1. ν”„λ΅μ νΈ λ””λ ‰ν† λ¦¬ μ΄λ™
cd /path/to/bigdataptAI

# 2. μ„¤μ • νμΌ ν™•μΈ λ° μμ •
vi config/config.yaml
# - model_path: SOLAR λ¨λΈ κ²½λ΅ μ„¤μ •
# - data paths: λ°μ΄ν„° κ²½λ΅ μ„¤μ •
# - ν•μ΄νΌνλΌλ―Έν„° μ΅°μ • (ν•„μ”μ‹)

# 3. λ””λ ‰ν† λ¦¬ μƒμ„±
mkdir -p workspace/{data/hira/{raw,processed,cleaned},models,logs}
```

### 2λ‹¨κ³„: λ°μ΄ν„° μ¤€λΉ„

**μµμ… A: μ‹¤μ  HIRA λ°μ΄ν„° μ‚¬μ©**

`docs/01_HIRA_DATA_PREPARATION_GUIDE.md` λ¬Έμ„λ¥Ό μ°Έμ΅°ν•μ—¬ λ‹¤μμ„ μν–‰:

1. HIRA λΉ…λ°μ΄ν„°κ°λ°©μ‹μ¤ν…(https://opendata.hira.or.kr/) μ ‘μ†
2. ν•„μ”ν• ν†µκ³„ λ°μ΄ν„° λ‹¤μ΄λ΅λ“
3. QA ν•μ‹μΌλ΅ λ³€ν™
4. λ°μ΄ν„° μ •μ  λ° λ¶„ν• 

```bash
# λ°μ΄ν„° μ •μ  μ¤ν¬λ¦½νΈ μ‹¤ν–‰
python 01_data_cleaning.py
```

**μµμ… B: ν…μ¤νΈ λ°μ΄ν„° μ‚¬μ©**

ν•™μµ λ…ΈνΈλ¶ μ‹¤ν–‰ μ‹ μλ™μΌλ΅ ν…μ¤νΈ λ°μ΄ν„°κ°€ μƒμ„±λ©λ‹λ‹¤.

### 3λ‹¨κ³„: λ¨λΈ ν•™μµ

**λ°©λ²• 1: JupyterLab λ…ΈνΈλ¶ μ‚¬μ© (κ¶μ¥)**

```bash
# JupyterLab μ‹¤ν–‰
jupyter lab

# λΈλΌμ°μ €μ—μ„ λ‹¤μ λ…ΈνΈλ¶ μ—΄κΈ°:
# notebooks/HIRA_Training_SOLAR_LoRA.ipynb

# μ…€μ„ μμ°¨μ μΌλ΅ μ‹¤ν–‰
```

**λ°©λ²• 2: Python μ¤ν¬λ¦½νΈ μ‚¬μ©**

```bash
# κ²€μ¦ ν¬ν•¨ ν•™μµ μ¤ν¬λ¦½νΈ
python 02_train_with_validation.py

# λλ” κΈ°λ³Έ μ¤ν¬λ¦½νΈ
python train_solar
```

### 4λ‹¨κ³„: λ¨λΈ ν‰κ°€ λ° ν…μ¤νΈ

**JupyterLab μΈν„°νμ΄μ¤:**

```bash
# notebooks/HIRA_Interface.ipynb μ—΄κΈ°
# μΈν„°λ™ν‹°λΈ μ§μμ‘λ‹µ ν…μ¤νΈ
```

**Flask μ›Ή μΈν„°νμ΄μ¤:**

```bash
# Flask μ„λ²„ μ‹¤ν–‰
python 03_improved_interface.py

# λΈλΌμ°μ €μ—μ„ μ ‘μ†
# http://localhost:8888
```

---

## π“ μƒμ„Έ κ°€μ΄λ“

### 1. λ°μ΄ν„° μ¤€λΉ„

**λ¬Έμ„**: `docs/01_HIRA_DATA_PREPARATION_GUIDE.md`

μ£Όμ” λ‚΄μ©:
- μ‹¬ν‰μ› λΉ…λ°μ΄ν„°κ°λ°©μ‹μ¤ν… μ†κ°
- λ°μ΄ν„° μμ§‘ μ „λµ
- QA λ°μ΄ν„° κµ¬μ΅° μ„¤κ³„
- λ°μ΄ν„° μƒμ„± λ°©λ²•λ΅ 
- ν’μ§ κ΄€λ¦¬ κΈ°μ¤€

**λ°μ΄ν„° ν•μ‹**:

```json
{
  "instruction": "κ±΄κ°•λ³΄ν— λΉ…λ°μ΄ν„° μ „λ¬Έκ°€λ΅μ„ μ •ν™•ν•κ² λ‹µλ³€ν•μ„Έμ”.",
  "input": "2023λ…„ MRI κ²€μ‚¬ κ±΄μλ” μ–Όλ§λ‚ λλ‚μ”?",
  "output": "2023λ…„ κ±΄κ°•λ³΄ν— μ μ© MRI κ²€μ‚¬λ” μ΄ 4,251,032κ±΄μ΄ μ‹ν–‰λμ—μµλ‹λ‹¤.",
  "metadata": {
    "category": "μ§„λ£ν†µκ³„",
    "source": "HIRA",
    "year": 2023
  }
}
```

### 2. λ¨λΈ ν•™μµ

**λ…ΈνΈλ¶**: `notebooks/HIRA_Training_SOLAR_LoRA.ipynb`

μ£Όμ” λ‹¨κ³„:
1. ν™κ²½ μ„¤μ • λ° GPU ν™•μΈ
2. λ°μ΄ν„° λ΅λ“ λ° μ „μ²λ¦¬
3. SOLAR-10.7B λ¨λΈ λ΅λ“
4. LoRA μ„¤μ • λ° μ μ©
5. ν•™μµ μ‹¤ν–‰
6. λ¨λΈ μ €μ¥ λ° ν‰κ°€

**μ£Όμ” νλΌλ―Έν„°**:

```yaml
LoRA:
  r: 16
  lora_alpha: 32
  lora_dropout: 0.05

Training:
  batch_size: 2
  gradient_accumulation_steps: 4
  learning_rate: 2e-4
  num_epochs: 10
  max_length: 512
```

**ν•™μµ μ‹κ°„**:
- A100 80G x2 κΈ°μ¤€
- 3,000κ° μƒν”: μ•½ 2-3μ‹κ°„
- 10,000κ° μƒν”: μ•½ 6-8μ‹κ°„

### 3. λ¨λΈ ν‰κ°€

**λ…ΈνΈλ¶**: `notebooks/HIRA_Interface.ipynb`

ν‰κ°€ λ°©λ²•:
1. **μΈν„°λ™ν‹°λΈ ν…μ¤νΈ**: μ‹¤μ‹κ°„ μ§μμ‘λ‹µ
2. **λ°°μΉ ν‰κ°€**: λ―Έλ¦¬ μ •μλ ν…μ¤νΈ μ„ΈνΈ
3. **νλΌλ―Έν„° λΉ„κµ**: Temperature λ“± μ‹¤ν—
4. **μ„±λ¥ λ¶„μ„**: μƒμ„± μ‹κ°„, ν† ν° μ λ“±

**ν‰κ°€ μ§€ν‘**:
- μƒμ„± μ‹κ°„ (μ΄)
- μƒμ„± ν† ν° μ
- λ‹µλ³€ ν’μ§ (1-5μ )
- μ‚¬μ‹¤ μ •ν™•μ„±
- Hallucination λ°μƒλ¥ 

---

## β™οΈ μ„¤μ • νμΌ

**νμΌ**: `config/config.yaml`

μ£Όμ” μ„Ήμ…:

```yaml
paths:
  model_path: "solar_10.7b_package/model"
  data: {...}
  output: {...}

lora:
  r: 16
  lora_alpha: 32
  target_modules: [...]

training:
  batch_size: 2
  learning_rate: 2e-4
  num_epochs: 10

inference:
  temperature: 0.3
  max_new_tokens: 256
```

### κ²½λ΅ μμ • λ°©λ²•

1. `config/config.yaml` μ—΄κΈ°
2. `paths` μ„Ήμ…μ—μ„ ν™κ²½μ— λ§λ” μ λ€/μƒλ€ κ²½λ΅ μ„¤μ •
3. μ €μ¥ ν›„ λ…ΈνΈλ¶/μ¤ν¬λ¦½νΈ μ‹¤ν–‰

---

## π”§ νΈλ¬λΈ”μν…

### GPU λ©”λ¨λ¦¬ λ¶€μ΅±

```python
# config.yamlμ—μ„ λ°°μΉ ν¬κΈ° μ¤„μ΄κΈ°
training:
  batch_size: 1  # 2μ—μ„ 1λ΅ λ³€κ²½
  gradient_accumulation_steps: 8  # 4μ—μ„ 8λ΅ μ¦κ°€
```

### λ¨λΈ λ΅λ“ μ¤λ¥

```bash
# κ²½λ΅ ν™•μΈ
ls solar_10.7b_package/model/

# ν•„μ νμΌ:
# - config.json
# - pytorch_model.bin (λλ” .safetensors)
# - tokenizer.json
# - tokenizer_config.json
```

### bitsandbytes μ¤λ¥

```python
# λ…ΈνΈλ¶/μ¤ν¬λ¦½νΈ μ²« λ¶€λ¶„μ— μ¶”κ°€
import sys
import os
os.environ['BITSANDBYTES_NOWELCOME'] = '1'
sys.modules['bitsandbytes'] = None
```

### νμ‡„λ§ ν™κ²½ μ„¤μ •

```python
# λ¨λΈ λ΅λ“ μ‹ local_files_only=True μ‚¬μ©
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    local_files_only=True,  # ν•„μ
    trust_remote_code=True
)
```

---

## π“ μ„±λ¥ λ²¤μΉλ§ν¬

### ν•™μµ μ„±λ¥ (μμƒ)

| μ—ν­ | Train Loss | Val Loss | μ‹κ°„ (A100x2) |
|------|-----------|----------|---------------|
| 1    | 1.245     | 1.182    | 15λ¶„          |
| 5    | 0.421     | 0.398    | 1μ‹κ°„ 15λ¶„    |
| 10   | 0.287     | 0.302    | 2μ‹κ°„ 30λ¶„    |

### μ¶”λ΅  μ„±λ¥

| λ©”νΈλ¦­            | κ°’           |
|------------------|--------------|
| ν‰κ·  μƒμ„± μ‹κ°„    | 1.2μ΄        |
| ν† ν°/μ΄          | 45 tokens/s  |
| ν‰κ·  λ‹µλ³€ κΈΈμ΄    | 120 ν† ν°     |
| GPU λ©”λ¨λ¦¬ μ‚¬μ©   | ~25GB        |

---

## π― λ‹¤μ λ‹¨κ³„

### λ‹¨κΈ° (1-2μ£Ό)

- [ ] μ‹¤μ  HIRA λ°μ΄ν„° μμ§‘ λ° μ •μ 
- [ ] μµμ† 3,000κ° QA μ μƒμ„±
- [ ] λ¨λΈ μ¬ν•™μµ λ° ν‰κ°€
- [ ] λ² μ΄μ¤λΌμΈ μ„±λ¥ μΈ΅μ •

### μ¤‘κΈ° (1κ°μ›”)

- [ ] λ°μ΄ν„° μ¦κ°• (5,000-10,000κ°)
- [ ] ν•μ΄νΌνλΌλ―Έν„° νλ‹
- [ ] A/B ν…μ¤ν…
- [ ] μ „λ¬Έκ°€ ν‰κ°€ μν–‰

### μ¥κΈ° (2-3κ°μ›”)

- [ ] RAG μ‹μ¤ν… ν†µν•©
- [ ] μ‹¤μ‹κ°„ λ°μ΄ν„° μ—…λ°μ΄νΈ νμ΄ν”„λΌμΈ
- [ ] Production λ°°ν¬
- [ ] λ¨λ‹ν„°λ§ μ‹μ¤ν… κµ¬μ¶•

---

## π“– μ°Έκ³  μλ£

### κ³µμ‹ λ¬Έμ„

- **HIRA λΉ…λ°μ΄ν„°κ°λ°©μ‹μ¤ν…**: https://opendata.hira.or.kr/
- **SOLAR λ¨λΈ**: https://huggingface.co/upstage/SOLAR-10.7B-v1.0
- **LoRA λ…Όλ¬Έ**: https://arxiv.org/abs/2106.09685
- **PEFT λΌμ΄λΈλ¬λ¦¬**: https://github.com/huggingface/peft

### ν”„λ΅μ νΈ λ¬Έμ„

1. `docs/01_HIRA_DATA_PREPARATION_GUIDE.md` - λ°μ΄ν„° μ¤€λΉ„ κ°€μ΄λ“
2. `config/config.yaml` - μ„¤μ • νμΌ
3. `SUMMARY.md` - ν”„λ΅μ νΈ μ”μ•½ (κΈ°μ΅΄)
4. `improvement_plan.md` - κ°μ„  κ³„ν (κΈ°μ΅΄)

### κ΄€λ ¨ μ½”λ“

- **Transformers**: https://github.com/huggingface/transformers
- **PyTorch**: https://pytorch.org/docs/
- **Flask**: https://flask.palletsprojects.com/

---

## π‘¥ κΈ°μ—¬μ

- **ν”„λ΅μ νΈ λ¦¬λ“**: [μ΄λ¦„]
- **ML μ—”μ§€λ‹μ–΄**: [μ΄λ¦„]
- **λ°μ΄ν„° μ „λ¬Έκ°€**: [μ΄λ¦„]
- **λ„λ©”μΈ μ „λ¬Έκ°€**: [μ΄λ¦„]

---

## π“ λΌμ΄μ„ μ¤

μ΄ ν”„λ΅μ νΈλ” [λΌμ΄μ„ μ¤ μ ν•]μ— λ”°λΌ λ°°ν¬λ©λ‹λ‹¤.

**μ£Όμμ‚¬ν•­**:
- HIRA λ°μ΄ν„°λ” κ³µκ³µλ°μ΄ν„°λ΅, μ΄μ©μ•½κ΄€μ„ μ¤€μν•΄μ•Ό ν•©λ‹λ‹¤.
- SOLAR λ¨λΈμ€ Apache 2.0 λΌμ΄μ„ μ¤μ…λ‹λ‹¤.
- μƒμ—…μ  μ΄μ© μ‹ λ³„λ„ ν™•μΈμ΄ ν•„μ”ν•  μ μμµλ‹λ‹¤.

---

## π“ λ¬Έμ

- **μ΄μ λ³΄κ³ **: GitHub Issues
- **κΈ°μ  λ¬Έμ**: [μ΄λ©”μΌ]
- **ν‘μ—… μ μ•**: [μ΄λ©”μΌ]

---

**λ§μ§€λ§‰ μ—…λ°μ΄νΈ**: 2025-11-13
**λ²„μ „**: 1.0.0
