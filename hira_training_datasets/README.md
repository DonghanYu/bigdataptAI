# HIRA í•™ìŠµ ë°ì´í„°ì…‹ v1.0

ê±´ê°•ë³´í—˜ì‹¬ì‚¬í‰ê°€ì›(HIRA) ë³´ê±´ì˜ë£Œë¹…ë°ì´í„° ê°œë°©ì‹œìŠ¤í…œ ê´€ë ¨ ê³ í’ˆì§ˆ í•™ìŠµ ë°ì´í„°ì…‹

## ğŸ“Š ë°ì´í„°ì…‹ ê°œìš”

### ìµœì¢… ê²°ê³¼
- **ì´ ë°ì´í„°**: 1,423ê°œ Q&A ìŒ
- **Train**: 1,136ê°œ (79.8%)
- **Val**: 140ê°œ (9.8%)
- **Test**: 147ê°œ (10.3%)

### ìƒì„± ê³¼ì •
```
323ê°œ (ìˆ˜ë™ íë ˆì´ì…˜)
   â†“ ê·œì¹™ ê¸°ë°˜ ì¦ê°• (ì–´ë¯¸/ì¡°ì‚¬/ë™ì˜ì–´ ë³€í˜•)
1,064ê°œ
   â†“ í…œí”Œë¦¿ ê¸°ë°˜ ìƒì„± (ì£¼ì œ/í‚¤ì›Œë“œ í™œìš©)
3,032ê°œ
   â†“ í’ˆì§ˆ ê²€ì¦ (í’ˆì§ˆ ì ìˆ˜ 0.6 ì´ìƒ)
1,423ê°œ (ìµœì¢…)
```

### í’ˆì§ˆ ì§€í‘œ
- **í‰ê·  í’ˆì§ˆ ì ìˆ˜**: 0.712
- **í’ˆì§ˆ ë¶„í¬**:
  - ìš°ìˆ˜ (0.9-1.0): 1ê°œ (0.1%)
  - ì–‘í˜¸ (0.8-0.9): 56ê°œ (3.9%)
  - ë³´í†µ (0.7-0.8): 373ê°œ (26.2%)
  - í—ˆìš© (0.6-0.7): 993ê°œ (69.8%)
- **í†µê³¼ìœ¨**: 46.9% (ì—„ê²©í•œ í’ˆì§ˆ ê¸°ì¤€)

## ğŸ—‚ï¸ ë°ì´í„° êµ¬ì¡°

### ë©”ë‰´ë³„ ë¶„í¬
| ë©”ë‰´ | Train | Val | Test | Total | ë¹„ìœ¨ |
|------|-------|-----|------|-------|------|
| ë³´ê±´ì˜ë£Œë¹…ë°ì´í„° | 277 | 34 | 36 | 347 | 24.4% |
| ì˜ë£Œí†µê³„ì •ë³´ | 251 | 31 | 32 | 314 | 22.1% |
| ê³ ê°ì§€ì› | 232 | 29 | 29 | 290 | 20.4% |
| ì„œë¹„ìŠ¤ ì†Œê°œ | 220 | 27 | 29 | 276 | 19.4% |
| ê³µê³µë°ì´í„° | 156 | 19 | 21 | 196 | 13.8% |

### ìƒì„± ë°©ë²•ë³„ ë¶„í¬
| ë°©ë²• | ê°œìˆ˜ | ë¹„ìœ¨ |
|------|------|------|
| í…œí”Œë¦¿ (what_is) | 328 | 23.0% |
| ì›ë³¸ | 174 | 12.2% |
| í…œí”Œë¦¿ (how_to) | 132 | 9.3% |
| ê·œì¹™ (ì¡°í•©) | 131 | 9.2% |
| í…œí”Œë¦¿ (ì¡°í•©) | 123 | 8.6% |
| ê¸°íƒ€ | 535 | 37.7% |

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
hira_training_datasets/
â”œâ”€â”€ output/v1.0/
â”‚   â”œâ”€â”€ full/
â”‚   â”‚   â”œâ”€â”€ train.json          # Train ë°ì´í„° (ë©”íƒ€ë°ì´í„° í¬í•¨)
â”‚   â”‚   â”œâ”€â”€ train.jsonl         # LoRA í•™ìŠµìš© (ë©”íƒ€ë°ì´í„° ì œì™¸) â­
â”‚   â”‚   â”œâ”€â”€ val.json            # Validation ë°ì´í„°
â”‚   â”‚   â””â”€â”€ test.json           # Test ë°ì´í„°
â”‚   â”œâ”€â”€ by_menu/
â”‚   â”‚   â”œâ”€â”€ service_intro/
â”‚   â”‚   â”œâ”€â”€ healthcare_bigdata/
â”‚   â”‚   â”œâ”€â”€ medical_statistics/
â”‚   â”‚   â”œâ”€â”€ public_data/
â”‚   â”‚   â””â”€â”€ customer_support/
â”‚   â””â”€â”€ metadata/
â”‚       â”œâ”€â”€ source_analysis.json       # ì†ŒìŠ¤ ë°ì´í„° ë¶„ì„
â”‚       â”œâ”€â”€ quality_report.json        # í’ˆì§ˆ ê²€ì¦ ë¦¬í¬íŠ¸
â”‚       â””â”€â”€ dataset_statistics.json    # ë°ì´í„°ì…‹ í†µê³„
â”œâ”€â”€ source_data/
â”‚   â”œâ”€â”€ hira_source.json        # ì›ë³¸ ë°ì´í„° (YAML ë³€í™˜)
â”‚   â””â”€â”€ hira_qa_only.json       # Q&Aë§Œ ì¶”ì¶œ
â”œâ”€â”€ config/
â”‚   â””â”€â”€ question_templates.yaml # ì§ˆë¬¸ í…œí”Œë¦¿
â”œâ”€â”€ 01_analyze_source_data.py   # ë°ì´í„° ë¶„ì„
â”œâ”€â”€ 02_rule_based_augment.py    # ê·œì¹™ ê¸°ë°˜ ì¦ê°•
â”œâ”€â”€ 03_template_based_generate.py # í…œí”Œë¦¿ ê¸°ë°˜ ìƒì„±
â”œâ”€â”€ 04_quality_check.py         # í’ˆì§ˆ ê²€ì¦
â”œâ”€â”€ 05_split_dataset.py         # ë°ì´í„°ì…‹ ë¶„í• 
â””â”€â”€ README.md                   # ì´ íŒŒì¼
```

## ğŸš€ ì‚¬ìš© ë°©ë²•

### 1. LoRA í•™ìŠµìš© ë°ì´í„° ì‚¬ìš©

```python
# train.jsonl í˜•ì‹
{"instruction": "ìƒë³‘ì½”ë“œëŠ” ì–´ë–»ê²Œ ì¡°íšŒí•˜ë‚˜ìš”?", "input": "", "output": "ìƒë³‘ì½”ë“œ(KCD ì½”ë“œ)ëŠ”..."}
```

**LoRA í•™ìŠµ ì˜ˆì‹œ:**
```bash
python3 train_lora.py \
  --data output/v1.0/full/train.jsonl \
  --val-data output/v1.0/full/val.json \
  --epochs 3 \
  --batch-size 16
```

### 2. ë°ì´í„° ë¶„ì„

```python
import json

# ì „ì²´ ë°ì´í„° ë¡œë“œ
with open('output/v1.0/full/train.json', 'r', encoding='utf-8') as f:
    train_data = json.load(f)

# ë©”íƒ€ë°ì´í„° í™•ì¸
for qa in train_data[:5]:
    print(f"Q: {qa['instruction']}")
    print(f"A: {qa['output'][:50]}...")
    print(f"ë©”ë‰´: {qa['metadata']['menu_name']}")
    print(f"í’ˆì§ˆ: {qa['metadata']['quality_score']:.3f}\n")
```

### 3. ë©”ë‰´ë³„ ë°ì´í„° ì‚¬ìš©

```python
# íŠ¹ì • ë©”ë‰´ë§Œ í•™ìŠµ
menu = "healthcare_bigdata"
train_path = f"output/v1.0/by_menu/{menu}/train.json"

with open(train_path, 'r', encoding='utf-8') as f:
    menu_data = json.load(f)

print(f"{menu}: {len(menu_data)}ê°œ")
```

## ğŸ“ˆ ë°ì´í„° í’ˆì§ˆ

### ì§ˆë¬¸ íŠ¹ì„±
- **í‰ê·  ê¸¸ì´**: 16.3ì
- **ê¸¸ì´ ë²”ìœ„**: 5-50ì
- **ì£¼ìš” ìœ í˜•**:
  - ë°©ë²• ì§ˆë¬¸ (how_to): "ì–´ë–»ê²Œ ~í•˜ë‚˜ìš”?"
  - ì •ì˜ ì§ˆë¬¸ (what_is): "~ê°€ ë­”ê°€ìš”?"
  - ìœ„ì¹˜ ì§ˆë¬¸ (where): "ì–´ë””ì„œ ~í•˜ë‚˜ìš”?"
  - í™•ì¸ ì§ˆë¬¸ (confirmation): "~ê°€ëŠ¥í•œê°€ìš”?"

### ë‹µë³€ íŠ¹ì„±
- **í‰ê·  ê¸¸ì´**: 88.4ì
- **ê¸¸ì´ ë²”ìœ„**: 20-350ì
- **êµ¬ì¡°**:
  - ë©”ë‰´ ê²½ë¡œ í¬í•¨: 8.7%
  - ë‹¨ê³„ë³„ ì„¤ëª…: 26.6%
  - ì˜ˆì‹œ í¬í•¨: 3.1%

## ğŸ”„ ì¬ìƒì„± ë°©ë²•

### ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
```bash
# 1. ë°ì´í„° ë¶„ì„
python3 01_analyze_source_data.py

# 2. ê·œì¹™ ê¸°ë°˜ ì¦ê°•
python3 02_rule_based_augment.py --multiplier 6

# 3. í…œí”Œë¦¿ ê¸°ë°˜ ìƒì„±
python3 03_template_based_generate.py --target 5000

# 4. í’ˆì§ˆ ê²€ì¦
python3 04_quality_check.py --min-score 0.6

# 5. ë°ì´í„°ì…‹ ë¶„í• 
python3 05_split_dataset.py --train 0.8 --val 0.1 --test 0.1
```

### íŒŒë¼ë¯¸í„° ì¡°ì •

**ë” ë§ì€ ë°ì´í„° ìƒì„±:**
```bash
# ì¦ê°• ë°°ìœ¨ ì¦ê°€
python3 02_rule_based_augment.py --multiplier 10

# ëª©í‘œ ê°œìˆ˜ ì¦ê°€
python3 03_template_based_generate.py --target 10000
```

**ë” ì—„ê²©í•œ í’ˆì§ˆ ê¸°ì¤€:**
```bash
# ìµœì†Œ ì ìˆ˜ ìƒí–¥
python3 04_quality_check.py --min-score 0.7
```

## ğŸ“Š í†µê³„ ìš”ì•½

### ìƒì„± ë‹¨ê³„ë³„
| ë‹¨ê³„ | ì…ë ¥ | ì¶œë ¥ | ì¦ê° |
|------|------|------|------|
| ê·œì¹™ ì¦ê°• | 323 | 1,064 | +741 (3.3x) |
| í…œí”Œë¦¿ ìƒì„± | 1,064 | 3,032 | +1,968 (2.8x) |
| í’ˆì§ˆ ê²€ì¦ | 3,032 | 1,423 | -1,609 (46.9% í†µê³¼) |

### ì œì™¸ ì‚¬ìœ 
- ë‚®ì€ í’ˆì§ˆ ì ìˆ˜ (<0.6): 1,609ê°œ (53.1%)
- ì¤‘ë³µ ì§ˆë¬¸: 0ê°œ
- ë¶€ì ì ˆí•œ ê¸¸ì´: 0ê°œ

## ğŸ¯ í™œìš© ì‚¬ë¡€

### 1. LLM íŒŒì¸íŠœë‹
- SOLAR-10.7B LoRA íŒŒì¸íŠœë‹
- GPT-3.5 Fine-tuning
- Claude Fine-tuning

### 2. RAG ì§€ì‹ë² ì´ìŠ¤
```python
# ë²¡í„° DB êµ¬ì¶•
from langchain.vectorstores import FAISS
from langchain.embeddings import HuggingFaceEmbeddings

# Q&A ë¡œë“œ ë° ì„ë² ë”©
documents = [f"{qa['instruction']} {qa['output']}" for qa in train_data]
vectorstore = FAISS.from_texts(documents, embeddings)
```

### 3. ì±—ë´‡ í•™ìŠµ ë°ì´í„°
```python
# Rasa í˜•ì‹ ë³€í™˜
for qa in train_data:
    print(f"- intent: ask_hira")
    print(f"  examples: |")
    print(f"    - {qa['instruction']}")
    print(f"  responses:")
    print(f"    - text: {qa['output']}\n")
```

## ğŸ” í’ˆì§ˆ ë³´ì¦

### ê²€ì¦ í•­ëª©
- âœ… ì¤‘ë³µ ì œê±° (0ê°œ ì¤‘ë³µ)
- âœ… ê¸¸ì´ ê²€ì¦ (Q: 5-100ì, A: 20-500ì)
- âœ… í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° (0.0-1.0)
- âœ… ì¼ê´€ì„± ê²€ì¦ (Q-A í‚¤ì›Œë“œ ë§¤ì¹­)
- âœ… ê· í˜•ì„± ê²€ì¦ (ë©”ë‰´ë³„ ë¶„í¬)

### í’ˆì§ˆ ì ìˆ˜ ê¸°ì¤€
```python
ì ìˆ˜ = ì§ˆë¬¸ í’ˆì§ˆ(0.4) + ë‹µë³€ í’ˆì§ˆ(0.4) + ì¼ê´€ì„±(0.2)

ì§ˆë¬¸ í’ˆì§ˆ:
  - ì ì • ê¸¸ì´
  - ì§ˆë¬¸ ë¶€í˜¸ ì¡´ì¬
  - ì˜ë¬¸ì‚¬ í¬í•¨
  - ì¤‘ë³µ ë‹¨ì–´ ì—†ìŒ

ë‹µë³€ í’ˆì§ˆ:
  - ì ì • ê¸¸ì´
  - ë‹µë³€ êµ¬ì¡°ì„±
  - ë©”ë‰´ ê²½ë¡œ í¬í•¨
  - ì˜ˆì‹œ í¬í•¨

ì¼ê´€ì„±:
  - Q-A í‚¤ì›Œë“œ ì¼ì¹˜ë„
  - ì£¼ìš” í‚¤ì›Œë“œ í¬í•¨
```

## ğŸ“ ë¼ì´ì„¼ìŠ¤

ë³¸ ë°ì´í„°ì…‹ì€ HIRA ì˜¤í”ˆë°ì´í„° í¬í„¸ì˜ ê³µê³µ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.

### ì‚¬ìš© ì¡°ê±´
- ì—°êµ¬ ë° í•™ìŠµ ëª©ì  ì‚¬ìš© ê°€ëŠ¥
- ìƒì—…ì  ì´ìš© ì‹œ HIRAì— ë¬¸ì˜ í•„ìš”
- ì¬ë°°í¬ ì‹œ ì¶œì²˜ ëª…ì‹œ í•„ìˆ˜

### ì¶œì²˜
- **ì›ë³¸ ë°ì´í„°**: ê±´ê°•ë³´í—˜ì‹¬ì‚¬í‰ê°€ì› (HIRA)
- **ë°ì´í„°ì…‹ ìƒì„±**: BigData PT AI í”„ë¡œì íŠ¸
- **ë²„ì „**: v1.0
- **ìƒì„±ì¼**: 2025-11-18

## ğŸ™ ê°ì‚¬

- **HIRA** - ë³´ê±´ì˜ë£Œë¹…ë°ì´í„° ê°œë°©
- **bigdata_portal_learning** - ìˆ˜ë™ íë ˆì´ì…˜ ë°ì´í„° ì œê³µ

## ğŸ“ ë¬¸ì˜

ë°ì´í„°ì…‹ ê´€ë ¨ ë¬¸ì˜: [GitHub Issues](https://github.com/DonghanYu/bigdataptAI/issues)

---

**ë²„ì „**: v1.0
**ìƒíƒœ**: âœ… LoRA í•™ìŠµ ì¤€ë¹„ ì™„ë£Œ
**ë‹¤ìŒ ë‹¨ê³„**: ëª¨ë¸ í•™ìŠµ ë° í‰ê°€
