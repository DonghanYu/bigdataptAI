#!/usr/bin/env python3
"""
HIRA ë°ì´í„°ì…‹ ë¶„í• 
- Train/Val/Test ë¶„í• 
- ë©”ë‰´ë³„ ë¶„í• 
- JSONL í˜•ì‹ ì €ì¥
- í†µê³„ ìƒì„±
"""

import json
import random
from pathlib import Path
from typing import List, Dict
from collections import defaultdict, Counter
import argparse
from datetime import datetime


class DatasetSplitter:
    """ë°ì´í„°ì…‹ ë¶„í• ê¸°"""

    def __init__(self, input_path: str):
        """ì´ˆê¸°í™”"""
        with open(input_path, 'r', encoding='utf-8') as f:
            self.data = json.load(f)

        # ëœë¤ ì‹œë“œ ê³ ì • (ì¬í˜„ì„±)
        random.seed(42)

        self.splits = {
            "train": [],
            "val": [],
            "test": []
        }

        self.by_menu = defaultdict(lambda: {"train": [], "val": [], "test": []})

        self.stats = {
            "total": len(self.data),
            "by_split": {},
            "by_menu": {},
            "by_generation_method": {}
        }

    def split(self, train_ratio: float = 0.8, val_ratio: float = 0.1, test_ratio: float = 0.1):
        """ë°ì´í„° ë¶„í• """
        print("="*80)
        print("ë°ì´í„°ì…‹ ë¶„í• ")
        print("="*80 + "\n")

        print(f"ì´ ë°ì´í„°: {len(self.data)}ê°œ")
        print(f"ë¶„í•  ë¹„ìœ¨: Train {train_ratio*100:.0f}% / Val {val_ratio*100:.0f}% / Test {test_ratio*100:.0f}%\n")

        # ë©”ë‰´ë³„ë¡œ ê·¸ë£¹í™”
        by_menu = defaultdict(list)
        for qa in self.data:
            menu = qa["metadata"]["menu"]
            by_menu[menu].append(qa)

        # ê° ë©”ë‰´ë³„ë¡œ ë¶„í•  (ê³„ì¸µì  ìƒ˜í”Œë§)
        for menu, qa_list in by_menu.items():
            random.shuffle(qa_list)

            total = len(qa_list)
            train_end = int(total * train_ratio)
            val_end = train_end + int(total * val_ratio)

            train = qa_list[:train_end]
            val = qa_list[train_end:val_end]
            test = qa_list[val_end:]

            self.splits["train"].extend(train)
            self.splits["val"].extend(val)
            self.splits["test"].extend(test)

            self.by_menu[menu]["train"] = train
            self.by_menu[menu]["val"] = val
            self.by_menu[menu]["test"] = test

        # ì„ê¸°
        random.shuffle(self.splits["train"])
        random.shuffle(self.splits["val"])
        random.shuffle(self.splits["test"])

        print(f"ë¶„í•  ê²°ê³¼:")
        print(f"  Train: {len(self.splits['train'])}ê°œ ({len(self.splits['train'])/len(self.data)*100:.1f}%)")
        print(f"  Val:   {len(self.splits['val'])}ê°œ ({len(self.splits['val'])/len(self.data)*100:.1f}%)")
        print(f"  Test:  {len(self.splits['test'])}ê°œ ({len(self.splits['test'])/len(self.data)*100:.1f}%)")

        # í†µê³„ ìˆ˜ì§‘
        self._collect_statistics()

        return self.splits

    def _collect_statistics(self):
        """í†µê³„ ìˆ˜ì§‘"""
        # ë¶„í• ë³„ í†µê³„
        for split_name, split_data in self.splits.items():
            self.stats["by_split"][split_name] = {
                "count": len(split_data),
                "avg_q_length": sum(qa["metadata"]["question_length"] for qa in split_data) / len(split_data) if split_data else 0,
                "avg_a_length": sum(qa["metadata"]["answer_length"] for qa in split_data) / len(split_data) if split_data else 0,
            }

        # ë©”ë‰´ë³„ í†µê³„
        for menu, splits in self.by_menu.items():
            self.stats["by_menu"][menu] = {
                "train": len(splits["train"]),
                "val": len(splits["val"]),
                "test": len(splits["test"]),
                "total": len(splits["train"]) + len(splits["val"]) + len(splits["test"])
            }

        # ìƒì„± ë°©ë²•ë³„ í†µê³„
        gen_methods = Counter()
        for qa in self.data:
            method = qa["metadata"]["generation_method"]
            gen_methods[method] += 1

        self.stats["by_generation_method"] = dict(gen_methods)

    def save_all(self, output_dir: str):
        """ëª¨ë“  í˜•ì‹ìœ¼ë¡œ ì €ì¥"""
        output_dir = Path(output_dir)

        # 1. Train/Val/Test JSON
        self._save_split_json(output_dir / "full")

        # 2. Train JSONL (LoRA í•™ìŠµìš©)
        self._save_train_jsonl(output_dir / "full" / "train.jsonl")

        # 3. ë©”ë‰´ë³„ JSON
        self._save_by_menu_json(output_dir / "by_menu")

        # 4. í†µê³„
        self._save_statistics(output_dir / "metadata" / "dataset_statistics.json")

        print(f"\nâœ… ëª¨ë“  íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_dir}")

    def _save_split_json(self, output_dir: Path):
        """Train/Val/Test JSON ì €ì¥"""
        output_dir.mkdir(parents=True, exist_ok=True)

        for split_name, split_data in self.splits.items():
            output_path = output_dir / f"{split_name}.json"

            with open(output_path, 'w', encoding='utf-8') as f:
                json.dump(split_data, f, ensure_ascii=False, indent=2)

            print(f"  {split_name}.json: {len(split_data)}ê°œ "
                  f"({output_path.stat().st_size/1024:.1f} KB)")

    def _save_train_jsonl(self, output_path: Path):
        """Train JSONL ì €ì¥ (LoRA í•™ìŠµìš©)"""
        output_path.parent.mkdir(parents=True, exist_ok=True)

        with open(output_path, 'w', encoding='utf-8') as f:
            for qa in self.splits["train"]:
                # ë©”íƒ€ë°ì´í„° ì œê±° (í•™ìŠµì— ë¶ˆí•„ìš”)
                train_item = {
                    "instruction": qa["instruction"],
                    "input": qa["input"],
                    "output": qa["output"]
                }
                f.write(json.dumps(train_item, ensure_ascii=False) + '\n')

        print(f"  train.jsonl: {len(self.splits['train'])}ê°œ "
              f"({output_path.stat().st_size/1024:.1f} KB)")

    def _save_by_menu_json(self, output_dir: Path):
        """ë©”ë‰´ë³„ JSON ì €ì¥"""
        output_dir.mkdir(parents=True, exist_ok=True)

        for menu, splits in self.by_menu.items():
            menu_dir = output_dir / menu
            menu_dir.mkdir(parents=True, exist_ok=True)

            for split_name, split_data in splits.items():
                output_path = menu_dir / f"{split_name}.json"

                with open(output_path, 'w', encoding='utf-8') as f:
                    json.dump(split_data, f, ensure_ascii=False, indent=2)

        print(f"  by_menu/: {len(self.by_menu)}ê°œ ë©”ë‰´")

    def _save_statistics(self, output_path: Path):
        """í†µê³„ ì €ì¥"""
        output_path.parent.mkdir(parents=True, exist_ok=True)

        stats_report = {
            "summary": {
                "total_data": self.stats["total"],
                "train_count": len(self.splits["train"]),
                "val_count": len(self.splits["val"]),
                "test_count": len(self.splits["test"]),
                "train_ratio": len(self.splits["train"]) / self.stats["total"],
                "val_ratio": len(self.splits["val"]) / self.stats["total"],
                "test_ratio": len(self.splits["test"]) / self.stats["total"],
            },
            "by_split": self.stats["by_split"],
            "by_menu": self.stats["by_menu"],
            "by_generation_method": self.stats["by_generation_method"],
            "timestamp": datetime.now().isoformat()
        }

        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(stats_report, f, ensure_ascii=False, indent=2)

        print(f"  statistics.json: í†µê³„ ë¦¬í¬íŠ¸")

    def print_statistics(self):
        """í†µê³„ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ğŸ“Š ë°ì´í„°ì…‹ í†µê³„")
        print("="*80)

        print(f"\nì „ì²´:")
        print(f"  ì´ ë°ì´í„°: {self.stats['total']}ê°œ")
        for split_name, split_stats in self.stats["by_split"].items():
            ratio = split_stats["count"] / self.stats["total"] * 100
            print(f"  {split_name.capitalize():5s}: {split_stats['count']:4d}ê°œ ({ratio:5.1f}%) "
                  f"[Q:{split_stats['avg_q_length']:.1f}ì, A:{split_stats['avg_a_length']:.1f}ì]")

        print(f"\në©”ë‰´ë³„:")
        print(f"  {'ë©”ë‰´':<20} {'Train':>7} {'Val':>7} {'Test':>7} {'Total':>7}")
        print("  " + "-"*54)

        for menu, menu_stats in sorted(self.stats["by_menu"].items()):
            print(f"  {menu:<20} {menu_stats['train']:7d} {menu_stats['val']:7d} "
                  f"{menu_stats['test']:7d} {menu_stats['total']:7d}")

        print(f"\nìƒì„± ë°©ë²•ë³„:")
        sorted_methods = sorted(
            self.stats["by_generation_method"].items(),
            key=lambda x: x[1],
            reverse=True
        )
        for method, count in sorted_methods[:10]:
            pct = (count / self.stats['total']) * 100
            print(f"  {method:25s}: {count:4d}ê°œ ({pct:5.1f}%)")


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    parser = argparse.ArgumentParser(description="HIRA ë°ì´í„°ì…‹ ë¶„í• ")
    parser.add_argument("--input", type=str,
                       default="output/temp/quality_filtered.json",
                       help="ì…ë ¥ íŒŒì¼ (í’ˆì§ˆ ê²€ì¦ ì™„ë£Œ)")
    parser.add_argument("--output", type=str,
                       default="output/v1.0",
                       help="ì¶œë ¥ ë””ë ‰í† ë¦¬")
    parser.add_argument("--train", type=float, default=0.8,
                       help="Train ë¹„ìœ¨ (default: 0.8)")
    parser.add_argument("--val", type=float, default=0.1,
                       help="Validation ë¹„ìœ¨ (default: 0.1)")
    parser.add_argument("--test", type=float, default=0.1,
                       help="Test ë¹„ìœ¨ (default: 0.1)")
    args = parser.parse_args()

    print("\n" + "="*80)
    print("HIRA ë°ì´í„°ì…‹ ë¶„í• ê¸° v1.0")
    print("="*80 + "\n")

    # ê²½ë¡œ ì„¤ì •
    base_dir = Path(__file__).parent
    input_path = base_dir / args.input
    output_dir = base_dir / args.output

    # ë¶„í• ê¸° ì´ˆê¸°í™”
    splitter = DatasetSplitter(input_path)

    # ë¶„í•  ì‹¤í–‰
    splits = splitter.split(
        train_ratio=args.train,
        val_ratio=args.val,
        test_ratio=args.test
    )

    # ì €ì¥
    splitter.save_all(output_dir)

    # í†µê³„
    splitter.print_statistics()

    print("\n" + "="*80)
    print("ğŸ‰ ë°ì´í„°ì…‹ ë¶„í•  ì™„ë£Œ!")
    print("="*80)

    print(f"\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
    print(f"  {output_dir}/full/train.json")
    print(f"  {output_dir}/full/train.jsonl  â† LoRA í•™ìŠµìš©")
    print(f"  {output_dir}/full/val.json")
    print(f"  {output_dir}/full/test.json")
    print(f"  {output_dir}/by_menu/...")
    print(f"  {output_dir}/metadata/dataset_statistics.json")

    print(f"\nğŸš€ LoRA í•™ìŠµ ì‹œì‘:")
    print(f"  python3 train_lora.py --data {output_dir}/full/train.jsonl")


if __name__ == "__main__":
    main()
