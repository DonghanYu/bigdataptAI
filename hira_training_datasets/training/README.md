# HIRA SOLAR-10.7B LoRA í•™ìŠµ ë° ì¶”ë¡ 

HIRA ë°ì´í„°ì…‹ìœ¼ë¡œ SOLAR-10.7B ëª¨ë¸ì„ LoRAë¡œ íŒŒì¸íŠœë‹í•˜ê³  ì›¹ ì¸í„°í˜ì´ìŠ¤ë¡œ í…ŒìŠ¤íŠ¸

## ğŸ“‹ ëª©ì°¨

- [í™˜ê²½ ìš”êµ¬ì‚¬í•­](#í™˜ê²½-ìš”êµ¬ì‚¬í•­)
- [ì„¤ì¹˜](#ì„¤ì¹˜)
- [1ë‹¨ê³„: í•™ìŠµ](#1ë‹¨ê³„-í•™ìŠµ)
- [2ë‹¨ê³„: ì¶”ë¡  ì¸í„°í˜ì´ìŠ¤](#2ë‹¨ê³„-ì¶”ë¡ -ì¸í„°í˜ì´ìŠ¤)
- [íŠ¸ëŸ¬ë¸”ìŠˆíŒ…](#íŠ¸ëŸ¬ë¸”ìŠˆíŒ…)

---

## ğŸ–¥ï¸ í™˜ê²½ ìš”êµ¬ì‚¬í•­

### í•„ìˆ˜
- **GPU**: NVIDIA GPU 16GB+ VRAM ê¶Œì¥ (RTX 3090, A100, V100 ë“±)
- **RAM**: 32GB+ ê¶Œì¥
- **Storage**: 50GB+ ì—¬ìœ  ê³µê°„
- **OS**: Linux (Ubuntu 20.04+ ê¶Œì¥)

### ì†Œí”„íŠ¸ì›¨ì–´
- Python 3.8+
- CUDA 11.8+ ë˜ëŠ” 12.1+
- PyTorch 2.0+

---

## ğŸ“¦ ì„¤ì¹˜

### 1. Python í™˜ê²½ ìƒì„±

```bash
# ê°€ìƒí™˜ê²½ ìƒì„± (ì„ íƒ)
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate  # Windows
```

### 2. í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜

```bash
cd /home/user/bigdataptAI/hira_training_datasets/training

# PyTorch ì„¤ì¹˜ (CUDA 12.1 ì˜ˆì‹œ)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# ë‚˜ë¨¸ì§€ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install -r requirements.txt
```

### 3. SOLAR ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

SOLAR-10.7B ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ê±°ë‚˜ ê²½ë¡œë¥¼ í™•ì¸í•˜ì„¸ìš”:

```bash
# ì˜µì…˜ 1: Hugging Faceì—ì„œ ë‹¤ìš´ë¡œë“œ
huggingface-cli download upstage/SOLAR-10.7B-v1.0 --local-dir ./models/solar-10.7b

# ì˜µì…˜ 2: ê¸°ì¡´ ëª¨ë¸ ê²½ë¡œ í™•ì¸
ls -la /home/work/LLM_Meditron/bigdataAI/solar_10.7b_package/model
```

---

## ğŸš€ 1ë‹¨ê³„: í•™ìŠµ

### ê¸°ë³¸ í•™ìŠµ

```bash
python3 train_lora.py \
  --model-path /home/work/LLM_Meditron/bigdataAI/solar_10.7b_package/model \
  --data-path ../output/v1.0/full \
  --output-path ./trained_models/hira_solar_lora \
  --num-epochs 3 \
  --batch-size 2 \
  --learning-rate 5e-5
```

### íŒŒë¼ë¯¸í„° ì„¤ëª…

| íŒŒë¼ë¯¸í„° | ì„¤ëª… | ê¸°ë³¸ê°’ |
|----------|------|--------|
| `--model-path` | SOLAR ëª¨ë¸ ê²½ë¡œ | (í•„ìˆ˜) |
| `--data-path` | ë°ì´í„° ê²½ë¡œ (train.jsonl í¬í•¨) | `../output/v1.0/full` |
| `--output-path` | í•™ìŠµ ëª¨ë¸ ì €ì¥ ê²½ë¡œ | `./trained_models/hira_solar_lora` |
| `--num-epochs` | í•™ìŠµ ì—í­ ìˆ˜ | 3 |
| `--batch-size` | ë°°ì¹˜ í¬ê¸° | 2 |
| `--gradient-accumulation-steps` | ê·¸ë˜ë””ì–¸íŠ¸ ëˆ„ì  | 4 |
| `--learning-rate` | í•™ìŠµë¥  | 5e-5 |
| `--max-length` | ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ | 512 |
| `--lora-r` | LoRA rank | 16 |
| `--lora-alpha` | LoRA alpha | 32 |
| `--lora-dropout` | LoRA dropout | 0.05 |

### ë©”ëª¨ë¦¬ ìµœì í™” ì˜µì…˜

**VRAM ë¶€ì¡± ì‹œ:**
```bash
python3 train_lora.py \
  --batch-size 1 \
  --gradient-accumulation-steps 8 \
  --max-length 256 \
  --lora-r 8
```

### í•™ìŠµ ëª¨ë‹ˆí„°ë§

í•™ìŠµ ì¤‘ ë‹¤ìŒ ì •ë³´ê°€ í‘œì‹œë©ë‹ˆë‹¤:
```
Step 100/1000 | Loss: 1.234 | LR: 5e-5
Eval Loss: 1.150 | Perplexity: 3.15
```

### ì˜ˆìƒ ì†Œìš” ì‹œê°„

| GPU | ë°°ì¹˜ í¬ê¸° | 1 ì—í­ ì‹œê°„ (1,136ê°œ) |
|-----|-----------|---------------------|
| RTX 3090 (24GB) | 2 | ~30ë¶„ |
| A100 (40GB) | 4 | ~20ë¶„ |
| V100 (16GB) | 1 | ~50ë¶„ |

---

## ğŸŒ 2ë‹¨ê³„: ì¶”ë¡  ì¸í„°í˜ì´ìŠ¤

### Gradio ì›¹ UI ì‹¤í–‰

```bash
python3 inference_interface.py \
  --base-model-path /home/work/LLM_Meditron/bigdataAI/solar_10.7b_package/model \
  --lora-adapter-path ./trained_models/hira_solar_lora/lora_adapter \
  --server-port 7860
```

### ì ‘ì†

ë¸Œë¼ìš°ì €ì—ì„œ ì ‘ì†:
```
http://localhost:7860
```

### ê³µê°œ ë§í¬ ìƒì„± (ì™¸ë¶€ ì ‘ì†)

```bash
python3 inference_interface.py \
  --base-model-path /path/to/solar \
  --lora-adapter-path ./trained_models/hira_solar_lora/lora_adapter \
  --share
```

### ì¸í„°í˜ì´ìŠ¤ ê¸°ëŠ¥

1. **ì§ˆë¬¸ ì…ë ¥**: HIRA ê´€ë ¨ ì§ˆë¬¸ ì…ë ¥
2. **íŒŒë¼ë¯¸í„° ì¡°ì •**:
   - Temperature: ì°½ì˜ì„± ì¡°ì ˆ (0.1-2.0)
   - Top-p: ë‹¤ì–‘ì„± ì¡°ì ˆ (0.1-1.0)
   - Top-k: í† í° ì„ íƒ ë²”ìœ„ (1-100)
   - Max Length: ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´
3. **ì˜ˆì‹œ ì§ˆë¬¸**: 8ê°œ ìƒ˜í”Œ ì§ˆë¬¸ ì œê³µ

---

## ğŸ§ª í…ŒìŠ¤íŠ¸

### ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (Python)

```python
from inference_interface import HIRAInference

# ëª¨ë¸ ë¡œë“œ
inference = HIRAInference(
    base_model_path="/path/to/solar",
    lora_adapter_path="./trained_models/hira_solar_lora/lora_adapter"
)

# ì§ˆë¬¸
question = "ìƒë³‘ì½”ë“œëŠ” ì–´ë–»ê²Œ ì¡°íšŒí•˜ë‚˜ìš”?"
answer = inference.generate(question)

print(f"Q: {question}")
print(f"A: {answer}")
```

### ë°°ì¹˜ í…ŒìŠ¤íŠ¸

```python
questions = [
    "í™˜ìí‘œë³¸ ë°ì´í„° ì‹ ì²­ ë°©ë²•ì€?",
    "HIRA ë°ì´í„° ê·œëª¨ëŠ”?",
    "API í‚¤ ë°œê¸‰ ë°©ë²•"
]

answers = inference.batch_generate(questions)

for q, a in zip(questions, answers):
    print(f"Q: {q}\nA: {a}\n")
```

---

## ğŸ“Š í•™ìŠµ ê²°ê³¼ í™•ì¸

### ì €ì¥ëœ íŒŒì¼ êµ¬ì¡°

```
trained_models/hira_solar_lora/
â”œâ”€â”€ lora_adapter/              # LoRA ì–´ëŒ‘í„° (ì¶”ë¡ ì— ì‚¬ìš©)
â”‚   â”œâ”€â”€ adapter_config.json
â”‚   â”œâ”€â”€ adapter_model.bin
â”‚   â””â”€â”€ ...
â”œâ”€â”€ training_config.json       # í•™ìŠµ ì„¤ì •
â”œâ”€â”€ eval_results.json          # í‰ê°€ ê²°ê³¼
â””â”€â”€ checkpoint-*/              # ì²´í¬í¬ì¸íŠ¸ (ì„ íƒ)
```

### í‰ê°€ ê²°ê³¼ í™•ì¸

```bash
cat trained_models/hira_solar_lora/eval_results.json
```

```json
{
  "val_loss": 1.234,
  "perplexity": 3.45,
  "evaluated_at": "2025-11-18T12:00:00"
}
```

---

## âš ï¸ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### 1. CUDA Out of Memory

**ì¦ìƒ:**
```
RuntimeError: CUDA out of memory
```

**í•´ê²°:**
```bash
# ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
python3 train_lora.py --batch-size 1 --max-length 256

# LoRA rank ì¤„ì´ê¸°
python3 train_lora.py --lora-r 8 --lora-alpha 16
```

### 2. PyTorch CUDA ë²„ì „ ë¶ˆì¼ì¹˜

**ì¦ìƒ:**
```
RuntimeError: CUDA error: no kernel image is available for execution
```

**í•´ê²°:**
```bash
# CUDA ë²„ì „ í™•ì¸
nvidia-smi

# ë§ëŠ” PyTorch ì„¤ì¹˜
# CUDA 11.8
pip install torch --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch --index-url https://download.pytorch.org/whl/cu121
```

### 3. ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨

**ì¦ìƒ:**
```
OSError: Model file not found
```

**í•´ê²°:**
```bash
# ëª¨ë¸ ê²½ë¡œ í™•ì¸
ls -la /home/work/LLM_Meditron/bigdataAI/solar_10.7b_package/model

# ë˜ëŠ” Hugging Faceì—ì„œ ë‹¤ìš´ë¡œë“œ
huggingface-cli download upstage/SOLAR-10.7B-v1.0 --local-dir ./models/solar
```

### 4. Gradio ì ‘ì† ì•ˆ ë¨

**ì¦ìƒ:**
```
Connection refused
```

**í•´ê²°:**
```bash
# ë°©í™”ë²½ í™•ì¸
sudo ufw allow 7860

# í¬íŠ¸ ë³€ê²½
python3 inference_interface.py --server-port 8080

# ëª¨ë“  IP í—ˆìš©
python3 inference_interface.py --server-name 0.0.0.0
```

---

## ğŸ’¡ ì„±ëŠ¥ ìµœì í™” íŒ

### í•™ìŠµ ì†ë„ í–¥ìƒ

1. **Mixed Precision Training** (ìë™ ì ìš©)
   - FP16 ì‚¬ìš©ìœ¼ë¡œ ë©”ëª¨ë¦¬ ì ˆì•½ & ì†ë„ í–¥ìƒ

2. **Gradient Checkpointing**
   ```python
   model.gradient_checkpointing_enable()
   ```

3. **ë°ì´í„° ë³‘ë ¬í™”** (Multi-GPU)
   ```bash
   torchrun --nproc_per_node=2 train_lora.py ...
   ```

### ì¶”ë¡  ì†ë„ í–¥ìƒ

1. **ë°°ì¹˜ ì¶”ë¡ **
   ```python
   answers = inference.batch_generate(questions)
   ```

2. **KV Cache í™œìš©** (ìë™)

3. **ì–‘ìí™”** (INT8)
   ```python
   load_in_8bit=True  # ëª¨ë¸ ë¡œë”© ì‹œ
   ```

---

## ğŸ“š ì°¸ê³ 

### ê´€ë ¨ íŒŒì¼
- í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸: `train_lora.py`
- ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸: `inference_interface.py`
- ë°ì´í„°ì…‹: `../output/v1.0/full/train.jsonl`

### ì™¸ë¶€ ë§í¬
- [SOLAR ëª¨ë¸](https://huggingface.co/upstage/SOLAR-10.7B-v1.0)
- [LoRA ë…¼ë¬¸](https://arxiv.org/abs/2106.09685)
- [Gradio ë¬¸ì„œ](https://gradio.app/docs/)

---

## ğŸ“ ë¬¸ì˜

ë°ì´í„°ì…‹ ë˜ëŠ” í•™ìŠµ ê´€ë ¨ ë¬¸ì˜:
- GitHub Issues: [ë§í¬]
- ì´ë©”ì¼: [ì´ë©”ì¼]

---

**ë²„ì „**: 1.0.0
**ìƒì„±ì¼**: 2025-11-18
**ìƒíƒœ**: âœ… í•™ìŠµ ë° ì¶”ë¡  ì¤€ë¹„ ì™„ë£Œ
